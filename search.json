[
  {
    "objectID": "posts/2024-08-20-Things-About-Dickey-Fuller.html",
    "href": "posts/2024-08-20-Things-About-Dickey-Fuller.html",
    "title": "关于迪基-富勒检验",
    "section": "",
    "text": "时间序列模型是一种用于分析和预测时间序列数据的统计模型。这些模型通过识别数据中的趋势、季节性和其他模式，来预测未来的值。以下是关于时间序列模型的相关信息：\n\n\n时间序列模型定义为一个随机过程，即按时间排序的随机变量的集合。每个时刻的位置点作为一个随机变量，其取值是从一个分布中采样得到的。\n\n\n\n\n自回归模型 (AR)：根据历史观测值来预测未来时序。\n移动平均模型 (MA)：根据白噪声的系数加权和来预测未来时序。\n自回归移动平均模型 (ARMA)：结合了AR和MA的特点，同时考虑历史观测值和白噪声的影响。\n差分移动自回归模型 (ARIMA)：适用于有明显上升或下降趋势的数据集，通过差分使数据平稳后使用ARMA拟合。\n\n\n\n\n平稳性是指时间序列的统计特性（如均值、方差和自协方差）不随时间变化。如果时间序列有季节性和趋势性，则视为不平稳。平稳性是许多时间序列预测模型（如自回归模型）的基础。\n\n\n\n特征根是判断时间序列模型平稳性的关键。一个平稳时间序列模型的特征根都在单位圆内，这意味着模型是稳定的，能够提供可靠的预测。"
  },
  {
    "objectID": "posts/2024-08-20-Things-About-Dickey-Fuller.html#时间序列模型",
    "href": "posts/2024-08-20-Things-About-Dickey-Fuller.html#时间序列模型",
    "title": "关于迪基-富勒检验",
    "section": "",
    "text": "时间序列模型是一种用于分析和预测时间序列数据的统计模型。这些模型通过识别数据中的趋势、季节性和其他模式，来预测未来的值。以下是关于时间序列模型的相关信息：\n\n\n时间序列模型定义为一个随机过程，即按时间排序的随机变量的集合。每个时刻的位置点作为一个随机变量，其取值是从一个分布中采样得到的。\n\n\n\n\n自回归模型 (AR)：根据历史观测值来预测未来时序。\n移动平均模型 (MA)：根据白噪声的系数加权和来预测未来时序。\n自回归移动平均模型 (ARMA)：结合了AR和MA的特点，同时考虑历史观测值和白噪声的影响。\n差分移动自回归模型 (ARIMA)：适用于有明显上升或下降趋势的数据集，通过差分使数据平稳后使用ARMA拟合。\n\n\n\n\n平稳性是指时间序列的统计特性（如均值、方差和自协方差）不随时间变化。如果时间序列有季节性和趋势性，则视为不平稳。平稳性是许多时间序列预测模型（如自回归模型）的基础。\n\n\n\n特征根是判断时间序列模型平稳性的关键。一个平稳时间序列模型的特征根都在单位圆内，这意味着模型是稳定的，能够提供可靠的预测。"
  },
  {
    "objectID": "posts/2024-08-20-Things-About-Dickey-Fuller.html#特征根",
    "href": "posts/2024-08-20-Things-About-Dickey-Fuller.html#特征根",
    "title": "关于迪基-富勒检验",
    "section": "特征根",
    "text": "特征根\n特征根是线性代数中的一个重要概念，特别是在时间序列分析中。特征根与特征向量一起，构成了理解线性变换和动态系统行为的基础。以下是关于特征根的相关信息：\n\n特征根的定义\n特征根是线性代数中一个矩阵的特征方程的根，它表示矩阵对应的线性变换在特定方向上的伸缩因子。在时间序列分析中，特征根与时间序列的稳定性密切相关。\n\n\n特征根在时间序列分析中的应用\n\n平稳性检验：通过检查特征根的位置（是否在单位圆内），可以判断时间序列是否平稳。如果所有特征根都在单位圆内，则时间序列是平稳的，否则是非平稳的。\n模型选择：不同的时间序列模型（如AR、MA、ARMA）的特征根有不同的性质，这些性质可以帮助我们选择合适的模型进行分析和预测。\n\n\n\n特征根与时间序列稳定性的关系\n单位根与序列稳定性：如果一个时间序列的特征根包含单位根（即特征根的绝对值等于1），则该序列是非平稳的。单位根的存在意味着序列的统计特性会随时间变化，这可能会影响到时间序列的预测能力。\n特征方程：对于时间序列模型，特征方程是通过将模型的差分方程转化为代数方程得到的。例如，AR(1)模型的特征方程为 1−aZ=0，其中 a 是自回归系数，Z 是特征根\n对模型预测能力的影响：特征根的位置决定了时间序列模型的预测能力。平稳的时间序列模型（所有特征根都在单位圆内）可以提供可靠的短期预测，而非平稳序列可能需要通过差分等方法转换为平稳序列后才能进行有效预测。\n\n\n特征根的理解\n特征根是线性代数中的一个重要概念，它与矩阵的特征方程密切相关。特征方程是一个关于未知数λ的方程，这个方程是通过求解矩阵A减去λ倍的单位矩阵后的行列式等于0得到的。\n具体来说，对于一个n×n的矩阵A，其特征方程可以表示为： det(A - λI) = 0\n其中，det表示行列式，I是n×n的单位矩阵，λ是我们要求的特征根。\n这个特征方程的解，即特征根λ，具有特殊的意义。它表示矩阵A对应的线性变换在某个特定方向上的伸缩因子。换句话说，如果我们有一个向量v，它是对应于特征根λ的特征向量，那么矩阵A作用在这个向量上，就相当于把这个向量伸缩了λ倍。\n举个例子来说明这个概念：\n假设我们有一个2×2的矩阵A：\nA = [[3, 1],\n     [1, 3]]\n我们需要找到这个矩阵的特征根和特征向量。\n首先，我们写出特征方程： det(A - λI) = det([[3-λ, 1], [1, 3-λ]]) = (3-λ)^2 - 1 = λ^2 - 6λ + 8 = 0\n解这个方程，我们得到两个特征根： λ1 = 2, λ2 = 4\n接下来，我们分别求对应于这两个特征根的特征向量。\n对于λ1 = 2，我们解方程组(A - 2I)v = 0，得到一个特征向量v1 = [1, -1]^T（T表示转置）。\n对于λ2 = 4，我们解方程组(A - 4I)v = 0，得到另一个特征向量v2 = [1, 1]^T。\n现在，我们可以验证特征根的含义。对于特征向量v1 = [1, -1]^T，矩阵A作用在这个向量上得到的结果是： Av1 = A[1, -1]^T = [3 * 1 + 1(-1), 1  1 + 3*(-1)]^T = [2, -2]^T = 2*v1\n可以看到，矩阵A将特征向量v1伸缩了2倍，这与我们找到的特征根λ1 = 2是一致的。\n同样地，对于特征向量v2 = [1, 1]^T，矩阵A作用在这个向量上得到的结果是： Av2 = A[1, 1]^T = [3 * 1 + 1 * 1, 1 * 1 + 3 * 1]^T = [4, 4]^T = 4*v2\n矩阵A将特征向量v2伸缩了4倍，这与我们找到的特征根λ2 = 4也是一致的。\n通过这个例子，我们可以看到特征根确实表示了矩阵对应的线性变换在特定方向上的伸缩因子。\n\nimport numpy as np\nimport pandas as pd\nfrom statsmodels.tsa.stattools import adfuller, kpss\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n\n# 定义一个2x2矩阵\nA = np.array([[3, 1],\n              [1, 3]])\n\n# 使用numpy.linalg.eig函数计算特征根和特征向量\neigenvalues, eigenvectors = np.linalg.eig(A)\n\nprint(\"特征根:\", eigenvalues)\nprint(\"特征向量:\\n\", eigenvectors)\n\n# 生成一个非平稳的时间序列数据\nnp.random.seed(0)\ndata = np.cumsum(np.random.randn(100))\n\n# 将数据转换为pandas的Series对象\ndata_series = pd.Series(data)\n\n# 绘制时间序列图\n# data_series.plot()\n\n# 进行DF检验\nresult_df = adfuller(data_series)\n\n# 输出DF检验结果\nprint('ADF Statistic:', result_df[0])\nprint('p-value:', result_df[1])\nprint('Critical Values:', result_df[4])\n\n# 根据p-value判断是否拒绝原假设\nif result_df[1] &lt; 0.05:\n    print('拒绝原假设，序列是平稳的')\nelse:\n    print('接受原假设，序列是非平稳的')\n\n\n# 进行ADF检验\nresult_adf = adfuller(data_series, regression='c', autolag='AIC')\n\n# 输出ADF检验结果\nprint('ADF Statistic:', result_adf[0])\nprint('p-value:', result_adf[1])\nprint('Critical Values:', result_adf[4])\n\n# 根根据p-value判断是否拒绝原假设\nif result_adf[1] &lt; 0.05:\n    print('拒绝原假设，序列是平稳的')\nelse:\n    print('接受原假设，序列是非平稳的')\n\n# 进行KPSS检验\nresult_kpss = kpss(data_series, regression='c')\n\n# 输出KPSS检验结果\nprint('KPSS Statistic:', result_kpss[0])\nprint('p-value:', result_kpss[1])\nprint('Critical Values:', result_kpss[3])\n\n# 根据p-value判断是否拒绝原假设\nif result_kpss[1] &gt; 0.05:\n    print('拒绝原假设，序列是平稳的')\nelse:\n    print('接受原假设，序列是非平稳的')\n\n特征根: [4. 2.]\n特征向量:\n [[ 0.70710678 -0.70710678]\n [ 0.70710678  0.70710678]]\nADF Statistic: -1.1320384625097901\np-value: 0.7021277385898382\nCritical Values: {'1%': -3.498198082189098, '5%': -2.891208211860468, '10%': -2.5825959973472097}\n接受原假设，序列是非平稳的\nADF Statistic: -1.1320384625097901\np-value: 0.7021277385898382\nCritical Values: {'1%': -3.498198082189098, '5%': -2.891208211860468, '10%': -2.5825959973472097}\n接受原假设，序列是非平稳的\nKPSS Statistic: 1.1001161286471666\np-value: 0.01\nCritical Values: {'10%': 0.347, '5%': 0.463, '2.5%': 0.574, '1%': 0.739}\n接受原假设，序列是非平稳的\n\n\nC:\\Users\\win10\\AppData\\Local\\Temp\\ipykernel_15296\\3430932899.py:56: InterpolationWarning: The test statistic is outside of the range of p-values available in the\nlook-up table. The actual p-value is smaller than the p-value returned.\n\n  result_kpss = kpss(data_series, regression='c')\n\n\nDF检验，也称为Dickey-Fuller检验，是一种用于检验时间序列数据是否含有单位根的统计方法。单位根是指一个时间序列的期望值不为零，但其自协方差函数仅依赖于时间间隔的长度，而不依赖于时间的起点。这种特性使得时间序列数据表现出非平稳性，即它们的统计特性会随时间变化。DF检验的基本思想是通过检验时间序列的回归模型中的自回归系数是否为零来确定是否存在单位根。以下是DF检验的相关信息：\n\n\nDF检验的基本原理\nDF检验通过检验时间序列的回归模型中的自回归系数是否为零来确定是否存在单位根。如果自回归系数显著不为零，则表明序列含有单位根，即序列是非平稳的。\n\n\nDF检验的应用场景\nDF检验广泛应用于经济学、金融学和统计学等领域，用于检验时间序列数据的平稳性。例如，在经济学中，它可以帮助分析经济增长率、通货膨胀率等时间序列数据的稳定性。\n\n\nDF检验的优缺点\n优点：DF检验是一种简单且易于实施的统计方法，适用于均值比较的问题，并且可以处理样本大小不一致的情况。 缺点：DF检验对样本数据的正态性有一定要求，如果数据不符合正态分布，可能会影响检验结果的准确性。它只能比较两个样本均值之间的差异，不能提供对多个样本进行比较的信息。\n\n\nDF检验与ADF检验的区别\nDF检验是最早提出的单位根检验方法之一，它是建立在一个简单的自回归模型(AR(1))上的。相比之下，ADF检验使用了更复杂的自回归模型，并且引入了趋势项来对序列的趋势进行建模，从而提高了检验的适用性和准确性。 DF检验只能应用于一阶情况，当序列存在高阶的滞后相关时，可以使用ADF检验，所以说ADF是对DF检验的扩展。\n\nimport statsmodels.api as sm\nimport numpy as np\n\n# 假设我们有以下数据\nx = np.array([1, 2, 3, 4, 5])\ny = np.array([2, 3, 4, 5, 6])\nprint(x)\n# 添加截距项\nx = sm.add_constant(x)\n\nprint(x)\n\n# 拟合线性回归模型\n# model = sm.OLS(y, x).fit()\n\n# # 输出模型摘要\n# print(model.summary())\n\n# # 预测\n# predictions = model.predict(x)\n# print(\"预测值:\", predictions)\n\n[1 2 3 4 5]\n[[1. 1.]\n [1. 2.]\n [1. 3.]\n [1. 4.]\n [1. 5.]]"
  },
  {
    "objectID": "posts/2024-08-20-Things-About-Dickey-Fuller.html#赫斯特hurst指数",
    "href": "posts/2024-08-20-Things-About-Dickey-Fuller.html#赫斯特hurst指数",
    "title": "关于迪基-富勒检验",
    "section": "赫斯特（Hurst）指数",
    "text": "赫斯特（Hurst）指数\n赫斯特（Hurst）指数是一种用于分析时间序列数据的统计工具，主要用于衡量时间序列的长期记忆性或自相关性。赫斯特指数是由英国水文学家哈罗德·赫斯特（Harold Edwin Hurst）在20世纪50年代提出的，最初用于分析尼罗河的水位变化。\n赫斯特指数的取值范围在0到1之间，可以分为以下几种情况：\nH = 0.5：时间序列是随机的，没有自相关性。这种情况下，时间序列的未来值与过去值之间没有任何关系。\n0.5 &lt; H &lt; 1：时间序列具有长期记忆性，即未来的趋势与过去的趋势有关。这种情况下，时间序列呈现出持久性（persistence），即如果过去是上升的，未来也很可能继续上升；如果过去是下降的，未来也很可能继续下降。\n0 ≤ H &lt; 0.5：时间序列具有反记忆性（antipersistence），即未来的趋势与过去的趋势相反。这种情况下，时间序列呈现出均值回归（mean reversion）的特性，即如果过去是上升的，未来很可能下降；如果过去是下降的，未来很可能上升。\n赫斯特指数的计算方法有很多种，其中最常用的是重标极差法（Rescaled Range Analysis, R/S）。以下是计算赫斯特指数的基本步骤：\n\n将时间序列分成若干个等长的子序列。\n对每个子序列计算累积和（cumulative sum）。\n对每个子序列计算标准差（standard deviation）。\n计算每个子序列的重标极差（rescaled range），即累积和的最大值与最小值之差除以子序列的标准差。\n计算整个时间序列的重标极差均值。\n根据重标极差均值和时间序列的长度计算赫斯特指数。\n\n赫斯特指数在许多领域都有广泛的应用，如金融市场分析、气象学、水文学、地球物理学等。通过计算赫斯特指数，可以帮助我们了解时间序列数据的特性，预测未来趋势，以及评估不同时间序列之间的相关性。"
  },
  {
    "objectID": "posts/2024-08-20-Things-About-Dickey-Fuller.html#方差比检验",
    "href": "posts/2024-08-20-Things-About-Dickey-Fuller.html#方差比检验",
    "title": "关于迪基-富勒检验",
    "section": "方差比检验",
    "text": "方差比检验\n（Variance Ratio Test）是一种用于检验两个或多个独立样本方差是否相等的统计方法。它基于F分布，通过比较两组数据的方差来判断它们是否来自具有相同方差的总体。\n方差比检验的步骤如下：\n提出假设：\n原假设（H0）：两组数据的方差相等。 备择假设（H1）：两组数据的方差不等于相等。 计算检验统计量：\n计算两组数据的样本方差 ( s_1^2 ) 和 ( s_2^2 )。 计算方差比 ( VR = ) 或 ( VR = )，具体取决于哪组数据的方差较大。 根据样本大小 ( n_1 ) 和 ( n_2 )，查找F分布表，确定临界值 ( F_{/2} ) 和 ( F_{1-/2} )。 做出决策：\n如果 ( VR ) 落在拒绝域内（即 ( VR &lt; F_{/2} ) 或 ( VR &gt; F_{1-/2} )），则拒绝原假设，认为两组数据的方差不等于相等。 如果 ( VR ) 落在接受域内，则不拒绝原假设，认为两组数据的方差相等。 方差比检验的适用条件包括：\n样本是独立的。 样本来自正态分布的总体。 方差比检验通常用于比较两个独立样本的方差，但也可以扩展到多个样本的情况。 需要注意的是，方差比检验对样本大小和分布的正态性有一定的要求。如果样本大小较小或数据分布偏离正态性，检验结果可能不准确。在实际应用中，可以考虑使用其他统计方法，如Levene检验或Bartlett检验，来检验方差的齐性。"
  },
  {
    "objectID": "posts/2024-08-20-Things-About-Dickey-Fuller.html#半衰期检验",
    "href": "posts/2024-08-20-Things-About-Dickey-Fuller.html#半衰期检验",
    "title": "关于迪基-富勒检验",
    "section": "半衰期检验",
    "text": "半衰期检验\n半衰期检验（Half-Life Test）是一种用于评估放射性物质衰变速率的实验方法。在核物理学、化学和环境科学等领域，半衰期检验被广泛应用于研究放射性同位素的衰变特性。通过测量放射性物质在一定时间内的衰变量，可以计算出其半衰期，从而了解其衰变速率和放射性强度。\n半衰期检验的基本原理是：在一个封闭系统中，放射性物质的原子核会随着时间的推移逐渐衰变成其他元素或同位素。在衰变过程中，放射性物质的剩余量会按照一定的规律减少。半衰期是指放射性物质剩余量减少到原来的一半所需的时间。\n进行半衰期检验的步骤如下：\n准备样品：选择一个合适的放射性物质样品，并将其置于一个封闭的容器中。\n测量初始放射性强度：使用辐射探测器测量样品的初始放射性强度。\n等待一段时间：等待足够长的时间，使得样品的放射性强度发生明显变化。\n再次测量放射性强度：在等待时间结束后，再次使用辐射探测器测量样品的放射性强度。\n计算半衰期：根据两次测量的放射性强度和时间间隔，使用以下公式计算半衰期：\n[ t_{1/2} = ]\n其中，( t_{1/2} ) 是半衰期，( (2) ) 是自然对数的底数（约等于 0.693），( k ) 是衰变速率常数。\n分析结果：根据计算出的半衰期，分析放射性物质的衰变速率和放射性强度。\n需要注意的是，半衰期检验需要在专业的实验室环境中进行，并采取适当的安全措施，以防止辐射对人体的伤害。此外，半衰期检验的结果可能受到测量误差和其他因素的影响，因此需要进行多次实验并取平均值以提高准确性。\n半衰期检验（Half-Life Test）本身并不是专门用于测试时间序列的回归性和平稳性的方法。半衰期检验主要用于评估放射性物质衰变速率，而不是时间序列分析"
  },
  {
    "objectID": "posts/2024-08-20-Things-About-Dickey-Fuller.html#协整型adf检验",
    "href": "posts/2024-08-20-Things-About-Dickey-Fuller.html#协整型adf检验",
    "title": "关于迪基-富勒检验",
    "section": "协整型ADF检验",
    "text": "协整型ADF检验\n协整型ADF检验（Cointegration Augmented Dickey-Fuller Test）是一种用于检验两个或多个非平稳时间序列是否存在协整关系的统计方法。协整关系指的是两个或多个时间序列之间存在长期的稳定关系，即使它们各自是非平稳的。\n在进行协整型ADF检验之前，通常需要先对时间序列进行单位根检验，以确定它们是否为非平稳的。如果两个时间序列都是非平稳的，但它们的线性组合是平稳的，那么这两个时间序列之间存在协整关系。\n协整型ADF检验的基本步骤如下：\n单位根检验：首先对两个或多个时间序列分别进行单位根检验，确定它们是否为非平稳的。常用的单位根检验方法有 Augmented Dickey-Fuller (ADF) 检验和 Phillips-Perron (PP) 检验。\n估计协整关系：如果两个时间序列都是非平稳的，接下来需要估计它们之间的协整关系。这可以通过最小二乘法或其他回归方法来实现。\n协整型ADF检验：在估计出协整关系后，进行协整型ADF检验。这个检验实际上是检验残差序列是否平稳。如果残差序列是平稳的，那么两个时间序列之间存在协整关系；否则，它们之间不存在协整关系。\n解释结果：根据协整型ADF检验的结果，可以得出两个时间序列之间是否存在协整关系的结论。如果存在协整关系，那么可以利用这个关系进行预测和分析。\n需要注意的是，协整型ADF检验对样本大小和数据质量有一定的要求。如果样本太小或数据存在严重的自相关或异方差问题，检验结果可能不准确。在实际应用中，可以考虑使用其他协整检验方法，如 Engle-Granger 两步法或 Johansen 协整检验。\n\nimport numpy as np\nimport pandas as pd\nfrom statsmodels.tsa.stattools import adfuller\nfrom statsmodels.regression.linear_model import OLS\n\n# 生成两个非平稳的时间序列\nnp.random.seed(42)\nn = 100\nx = np.cumsum(np.random.randn(n))\ny = 2 * x + np.cumsum(np.random.randn(n))\n\n# 单位根检验\nresult_x = adfuller(x)\nresult_y = adfuller(y)\n\nprint(\"x 的单位根检验结果：\", result_x)\nprint(\"y 的单位根检验结果：\", result_y)\n\n# 估计协整关系\nmodel = OLS(y, x).fit()\nresiduals = model.resid\n\n# 协整型ADF检验\nresult_residuals = adfuller(residuals)\n\nprint(\"残差序列的单位根检验结果：\", result_residuals)\n\n# 解释结果\nalpha = 0.05\nif result_x[1] &gt; alpha and result_y[1] &gt; alpha and result_residuals[1] &lt; alpha:\n    print(\"x 和 y 存在协整关系\")\nelse:\n    print(\"x 和 y 不存在协整关系\")\n\nx 的单位根检验结果： (-1.3583317659818985, 0.6020814791099101, 0, 99, {'1%': -3.498198082189098, '5%': -2.891208211860468, '10%': -2.5825959973472097}, 222.8689980232281)\ny 的单位根检验结果： (-1.258001500815765, 0.6481611011736785, 1, 98, {'1%': -3.4989097606014496, '5%': -2.891516256916761, '10%': -2.5827604414827157}, 356.0626708213774)\n残差序列的单位根检验结果： (-1.9559190170990346, 0.3062290299375441, 0, 99, {'1%': -3.498198082189098, '5%': -2.891208211860468, '10%': -2.5825959973472097}, 237.03854879262025)\nx 和 y 不存在协整关系\n\n\n约翰森测试（Johansen Test），也称为约翰森协整检验（Johansen Cointegration Test），是一种用于检验多个非平稳时间序列之间是否存在长期稳定关系的统计方法。这种方法是基于向量自回归（VAR）模型，通过估计模型参数并构造相应的统计量来检验协整关系的存在性。以下是关于约翰森测试的详细介绍：\n\n约翰森测试的基本原理\n约翰森测试的核心思想是，如果两个或多个非平稳时间序列之间存在协整关系，那么它们的线性组合应该是平稳的。通过构建一个向量自回归（VAR）模型，并估计模型参数，可以检验这些时间序列的协整关系。\n\n\n约翰森测试的主要步骤\n\n建立VAR模型：首先确定VAR模型的最优滞后阶数，并估计模型参数。\n计算残差：对VAR模型进行估计后，计算模型的残差。\n单位根检验：对残差进行单位根检验，以判断是否存在协整关系。\n\n\n\n约翰森测试的结果解读\n\n特征值：特征值表示每个潜在协整关系的强度。特征值越接近1，表示协整关系越强。\n特征向量：特征向量表示协整关系的方向。\n似然比统计量：用于检验是否存在协整关系以及协整关系的数量。\n临界值：用于确定似然比统计量是否显著。\n\n\n\n约翰森测试的应用场景\n约翰森测试广泛应用于经济学和金融学领域，特别是用于研究股票价格、汇率、利率等变量之间的长期均衡关系。它可以帮助分析师判断两个或多个时间序列之间是否存在长期的稳定关系，从而为投资决策提供依据。\n\n\n约翰森测试与相关性检验的区别\n\n协整性：描述的是两个或多个非平稳时间序列之间存在的一种长期稳定关系。\n相关性：衡量的是两个时间序列之间的线性关系强度。\n\n约翰森测试的结果可以帮助我们避免使用非平稳数据进行回归分析所导致的“伪回归”问题，从而更准确地分析变量之间的长期均衡关系。在实际操作中，交易者通常会结合其他技术指标和市场分析来综合判断股票之间的协整性，以制定更为有效的交易策略。\n\nimport numpy as np  \nimport pandas as pd  \nfrom statsmodels.tsa.vector_ar.vecm import coint_johansen  \n  \n# 生成模拟数据  \nnp.random.seed(42)  \nt = np.linspace(0, 10, 100)  \nx1 = np.sin(t) + np.random.normal(0, 0.1, 100)  \nx2 = np.cos(t) + np.random.normal(0, 0.1, 100)  \nx3 = 0.5 * x1 + 0.5 * x2 + np.random.normal(0, 0.1, 100)  \n  \n# 将数据转换为DataFrame  \ndata = pd.DataFrame({'X1': x1, 'X2': x2, 'X3': x3})  \nprint(data)\n# 使用Johansen协整检验  \nmodel = coint_johansen(data, det_order=0, k_ar_diff=1)  \n  \n# 打印结果  \nprint(\"Johansen协整检验结果:\")  \nprint(\"\\n--- 迹统计量（Trace Statistics, lr1）---\")  \nprint(model.lr1)  \nprint(\"\\n--- 临界值（Critical Values，通常为1%、5%、10%显著性水平）---\")  \nprint(model.cvt)  \nprint(\"\\n--- 最大特征值统计量（Maximum Eigenvalue Statistics, lr2）---\")  \nprint(model.lr2)  \nprint(\"\\n--- 临界值（Critical Values，通常为1%、5%、10%显著性水平）---\")  \nprint(model.cvm)  \n  \n# 解释结果并打印的函数  \ndef print_rejection(stat, cv, name, significance_level=0.05):  \n    # 将显著性水平转换为列索引（cvt的第一行通常是显著性水平说明，从第二行开始是临界值）  \n    sig_levels = ['1%', '5%', '10%']  # 假设cvt的列标题是这样，实际情况可能不同  \n    col_index = sig_levels.index(f\"{significance_level*100:.0f}%\")  \n    if col_index == -1:  # 如果指定的显著性水平不在列表中，则默认使用5%  \n        col_index = 1  \n    print('cv[0]:',cv[0])\n    print('col_index:',col_index)\n    num_rejections = 0  \n    for value, c_value in zip(stat, cv[:, col_index]):  \n        if value &gt; c_value:  \n            num_rejections += 1  \n            print(f\"在{name}检验中，拒绝了不存在至少{num_rejections}个协整向量的原假设（统计量={value:.2f}，{significance_level*100:.0f}%临界值={c_value:.2f}）\")  \n        else:  \n            break  \n  \nprint_rejection(model.lr1, model.cvt, \"迹\",significance_level=0.05)\nprint_rejection(model.lr2, model.cvm, \"最大特征值\")  \n  \n# 得出结论  \n# 注意：由于迹统计量和最大特征值统计量可能会给出不同的结论，  \n# 我们通常根据其中一个或结合两者来得出结论。  \n# 在这里，我们简单地基于迹统计量的结果来得出结论。  \ncol_idx = 1\nprint('model.lr1 &gt; model.cvt[:, col_idx]:',model.lr1 &gt; model.cvt[:, col_idx])\nprint('np.any(model.lr1 &gt; model.cvt[:, col_idx]):',np.any(model.lr1 &gt; model.cvt[:, col_idx]))\nif np.any(model.lr1 &gt; model.cvt[:, col_idx]):  # 检查是否有拒绝发生  \n    num_cointegrating_vectors = np.sum(model.lr1 &gt; model.cvt[:, col_idx])  \n    print(f\"\\n结论：时间序列之间存在至少{num_cointegrating_vectors}个协整向量（基于迹统计量）。\")  \nelse:  \n    print(\"\\n结论：时间序列之间不存在协整向量（基于迹统计量）。\")  \n  \n# 注意：实际中，你可能需要更仔细地分析两个统计量的结果，  \n# 并考虑数据的性质、样本大小、滞后阶数的选择等因素来综合得出结论。\n\n          X1        X2        X3\n0   0.049671  0.858463  0.489846\n1   0.087012  0.952838  0.576004\n2   0.265418  0.945392  0.713710\n3   0.450717  0.874209  0.767843\n4   0.369721  0.903352  0.498769\n..       ...       ...       ...\n95 -0.316698 -0.946852 -0.701066\n96 -0.239231 -1.051570 -0.555440\n97 -0.338493 -0.915792 -0.596413\n98 -0.456126 -0.883832 -0.588693\n99 -0.567480 -0.953369 -0.697461\n\n[100 rows x 3 columns]\nJohansen协整检验结果:\n\n--- 迹统计量（Trace Statistics, lr1）---\n[144.34074724  83.97031191  37.69871001]\n\n--- 临界值（Critical Values，通常为1%、5%、10%显著性水平）---\n[[27.0669 29.7961 35.4628]\n [13.4294 15.4943 19.9349]\n [ 2.7055  3.8415  6.6349]]\n\n--- 最大特征值统计量（Maximum Eigenvalue Statistics, lr2）---\n[60.37043533 46.2716019  37.69871001]\n\n--- 临界值（Critical Values，通常为1%、5%、10%显著性水平）---\n[[18.8928 21.1314 25.865 ]\n [12.2971 14.2639 18.52  ]\n [ 2.7055  3.8415  6.6349]]\ncv[0]: [27.0669 29.7961 35.4628]\ncol_index: 1\n在迹检验中，拒绝了不存在至少1个协整向量的原假设（统计量=144.34，5%临界值=29.80）\n在迹检验中，拒绝了不存在至少2个协整向量的原假设（统计量=83.97，5%临界值=15.49）\n在迹检验中，拒绝了不存在至少3个协整向量的原假设（统计量=37.70，5%临界值=3.84）\ncv[0]: [18.8928 21.1314 25.865 ]\ncol_index: 1\n在最大特征值检验中，拒绝了不存在至少1个协整向量的原假设（统计量=60.37，5%临界值=21.13）\n在最大特征值检验中，拒绝了不存在至少2个协整向量的原假设（统计量=46.27，5%临界值=14.26）\n在最大特征值检验中，拒绝了不存在至少3个协整向量的原假设（统计量=37.70，5%临界值=3.84）\nmodel.lr1 &gt; model.cvt[:, col_idx]: [ True  True  True]\nnp.any(model.lr1 &gt; model.cvt[:, col_idx]): True\n\n结论：时间序列之间存在至少3个协整向量（基于迹统计量）。"
  },
  {
    "objectID": "posts/2024-07-25-random-walk.html",
    "href": "posts/2024-07-25-random-walk.html",
    "title": "随机漫步",
    "section": "",
    "text": "布朗运动是将看起来连成一片的液体，在高倍显微镜下看其实是由许许多多分子组成的。液体分子不停地做无规则的运动，不断地随机撞击悬浮微粒。当悬浮的微粒足够小的时候，由于受到的来自各个方向的液体分子的撞击作用是不平衡的。在某一瞬间，微粒在另一个方向受到的撞击作用超强的时候，致使微粒又向其它方向运动，这样，就引起了微粒的无规则的运动就是布朗运动。（布朗运动指的是分子迸出的微粒的随机运动，而不是分子的随机运动。）\n即布朗运动代表了一种随机涨落现象。普遍的观点仍认为，股票市场是随机波动的，随机波动是股票市场最根本的特性，是股票市场的常态。（随机现象的数学定义是：在个别试验中其结果呈现出不确定性；在大量重复试验中其结果又具有统计规律性的现象。）而布朗运动假设是现代资本市场理论的核心假设。"
  },
  {
    "objectID": "posts/2024-07-25-random-walk.html#几何布朗运动brownian-motion",
    "href": "posts/2024-07-25-random-walk.html#几何布朗运动brownian-motion",
    "title": "随机漫步",
    "section": "",
    "text": "布朗运动是将看起来连成一片的液体，在高倍显微镜下看其实是由许许多多分子组成的。液体分子不停地做无规则的运动，不断地随机撞击悬浮微粒。当悬浮的微粒足够小的时候，由于受到的来自各个方向的液体分子的撞击作用是不平衡的。在某一瞬间，微粒在另一个方向受到的撞击作用超强的时候，致使微粒又向其它方向运动，这样，就引起了微粒的无规则的运动就是布朗运动。（布朗运动指的是分子迸出的微粒的随机运动，而不是分子的随机运动。）\n即布朗运动代表了一种随机涨落现象。普遍的观点仍认为，股票市场是随机波动的，随机波动是股票市场最根本的特性，是股票市场的常态。（随机现象的数学定义是：在个别试验中其结果呈现出不确定性；在大量重复试验中其结果又具有统计规律性的现象。）而布朗运动假设是现代资本市场理论的核心假设。"
  },
  {
    "objectID": "posts/2024-07-25-random-walk.html#随机游走",
    "href": "posts/2024-07-25-random-walk.html#随机游走",
    "title": "随机漫步",
    "section": "随机游走",
    "text": "随机游走\n其概念接近于布朗运动，是布朗运动的理想数学状态。任何分子所带的守恒量都各自对应着一个扩散运输定律。\n随机游走过程\\(S_t\\)​遵循几何布朗运动，满足微分方程：\n\\(dS_t​=uS_t​d_t+σS_t​dW_t\\)\n\\(​dS_t​/S_t​=ud_t+σdW_t\\)\n​设定初试状态\\(S_0\\)，根据伊藤积分，可以解出：\n\\(S_t​=S_0​exp((u−σ^2/2)t+σW_t​)\\)\n在数学领域，函数exp(x)代表自然指数函数，即以实数e（e≈2.71828）为底的指数函数。其表达式为exp(x)=\\(e^x\\)\n所以上面的式子也可以写成：\n\\(S_t​=S_0​e^{(u−σ^2/2)t+σW_t​}\\)\n其中μ (‘百分比drift’) 和σ (‘百分比volatility’)是常量。\n漂移率（Drift Rate）： 在金融领域，漂移率指的是资产价格的平均变动率，用来衡量资产价格的趋势性。例如，股票价格的漂移率可以帮助投资者判断价格的长期趋势\n波动率（volatility） 波动性，在金融数学领域，指金融资产在一定时间段的变化性。通常以一年内涨落的标准差来测量。金融市场中，投资的波动性与其风险有着密切的联系。\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n#rect=[0.1,5.0,0.1,0.1]\nfig=plt.figure()\n\n #time span\nT=2\n#drift factor飘移率\nmu=0.1 \n#volatility波动率\nsigma=0.04 \n#t=0初试价\nS0=20 \n#length of steps\ndt=0.01 \nN=round(T/dt)\nt=np.linspace(0,T,N)\n\n#布朗运动\nW=np.random.standard_normal(size=N)\nW=np.cumsum(W)*np.sqrt(dt)\n\nX=(mu-0.5*sigma**2)*t+sigma*W\n\nS=S0*np.exp(X)\n\nplt.plot(t,S,lw=2)\nplt.show()"
  },
  {
    "objectID": "posts/2024-07-27-Algorithmic-Trading.html",
    "href": "posts/2024-07-27-Algorithmic-Trading.html",
    "title": "算法交易：制胜策略与原理(欧内斯特·陈)之一",
    "section": "",
    "text": "在均值回归交易策略所相关的系列当中，我们将讨论以多元的统计技术［如扩展版的迪基-富勒检验（Dickey-Fuller检验，即ADF检验）、赫斯特（Hurst）指数、方差比检验、半衰期检验模式等］来检测时间序列的均值回归之属性，以及相关的平稳性；同时，我们还要检测一个由金融工具所构建的投资组合之协整属性［相关检测模式包括协整型ADF检验（即CADF检验）、约翰森（Johansen）检验等］。除了前述这些统计测试模式被机械地应用于时间序列而外，我们还要努力传达一个直观的理解方法，即要认知相关测试的真正用意以及简易数学方程背后的深层含义。\n我们将解析一些具有均值回归属性之投资组合所相关的最简单的技术和策略模式［如线性交易模式、布林带线、卡尔曼过滤法则(Kalman filter)等］。\n这个可以用backtrader框架来实现"
  },
  {
    "objectID": "posts/2024-07-27-Algorithmic-Trading.html#泰勒连续展开公式",
    "href": "posts/2024-07-27-Algorithmic-Trading.html#泰勒连续展开公式",
    "title": "算法交易：制胜策略与原理(欧内斯特·陈)之一",
    "section": "泰勒连续展开公式",
    "text": "泰勒连续展开公式\n泰勒连续展开公式（Taylor Series Expansion）是数学中用于表示一个函数在某一点附近的一个无穷级数展开。这个公式是以英国数学家布鲁克·泰勒（Brook Taylor）的名字命名的。泰勒级数的基本思想是用一个函数在某一点附近的各阶导数值来代替该函数，从而得到一个关于变量的无穷级数表达式。\n泰勒连续展开公式的定义如下：设函数f(x)在点x=a的某邻域内具有n阶导数，那么对于这个区间上任意x，有：\nf(x) = f(a) + f’(a)(x-a) + f’’(a)(x-a)^2/2! + …+ fn(a)(x-a)n/n! + R_n(x)\n其中，f’(a)表示函数f的一阶导数在点a处的值，f’’(a)表示二阶导数在点a处的值，以此类推。R_n(x)是余项，它随着n的增大趋近于0。当n趋向于无穷大时，泰勒级数就变成了泰勒展开式。\n泰勒级数有很多实际应用，例如用于数值计算、求解微分方程、信号处理等领域。\n\n瞬时出现的数据信息会在瞬时之间即刻消失。这是因为对于相应的做市商与电子通信网络的运营商而言，他们没有义务向所有的交易参与方通报相关的价格信息。坦白地说，很多做市商将相关的交易信息视若珍宝，同时将对这些信息的掌控视为自身的专利与特权（他们这种做法很聪明，因为，如货币这般的高频交易策略往往要依赖于订单信息与价格信息，这一点我们在第7章会有所涉及。像银行之类金融机构中的外汇自营交易部门，就擅长于将前述的相关信息据为己有）。\n\n\n如果我们发现一个比较理想的概率，在其情境之下，应用相关交易策略所获取的收益不输于或好于随机的收益以及实际收益的观测值，那么，这并不意味着所谓的动量交易策略能够捕捉任何行情或收益，其之所以盈利是因为我们比较幸运，即攫取的收益率的观测数值所生成的概率分布恰巧具有一个特定的均值和分布形态。为了在规定的时刻内生成模拟的随机收益率的相应数据，我们可以从MATLAB系统中的统计软件内选取那些服从皮尔逊分布的随机数来创建相应的函数；在模拟收益率marketRet_sim生成之后，我们根据其变化创建模拟的价格序列cl_sim；最后，我们根据相应价格的变化运行相关的交易策略，同时计算该策略项下的平均收益率。我们需要模拟10000次，然后统计有多少次因此策略而产生的平均收益大于等于实际的观测数据。\n\n\n# Hypothesis Testing on a Futures Momentum Strategy\n\nimport numpy as np\nimport pandas as pd\n#from scipy.stats import describe\nfrom scipy.stats import pearson3\n\n# moments表示阶矩，pearsrnd表示皮尔逊分布，skewness表示收益率曲线的偏度，kurtosis指峰度值，long代表多头（买方），short代表空头（卖方），backshift指二次变分，pos指持仓头寸。\ndf=pd.read_csv('datas/TU.csv')\ndf['Time']=pd.to_datetime(df['Time']).dt.date # remove HH:MM:SS\ndf.set_index('Time', inplace=True)\n\nlookback=250\nholddays=25\n\n# 使用shift()方法将数据向下移动一行\nlongs= df['Close'] &gt; df['Close'].shift()\nshorts= df['Close'] &lt; df['Close'].shift()\n\npos=np.zeros(df.shape[0])\n\nfor h in range(0, holddays):\n    long_lag=longs.shift(h)\n    long_lag[long_lag.isna()]=False\n    long_lag=long_lag.astype(bool)\n\n    short_lag=shorts.shift(h)\n    short_lag[short_lag.isna()]=False\n    short_lag=short_lag.astype(bool)\n\n    pos[long_lag]=pos[long_lag]+1\n    pos[short_lag]=pos[short_lag]-1\n    \ncapital=np.nansum(np.array(pd.DataFrame(abs(pos)).shift()), axis=1)\npos[capital==0,]=0\ncapital[capital==0]=1\n# pct_change()方法是pandas库中DataFrame和Series对象的一个常用方法，用于计算数据的变化百分比。\n# 该方法计算相邻行之间的相对变化，并返回一个新的Series或DataFrame，其中包含每个元素相对于前一个元素的百分比变化。\n# 计算收盘价的每日百分比变化，得到一个包含每日收益率的Series对象。\nmarketRet=df['Close'].pct_change()\n# pd.DataFrame(pos).shift()：将持仓（pos）转换为DataFrame对象，并将其向上移动一行。这样做的目的是为了计算每个持仓在下一交易日的表现。\n# np.array(pd.DataFrame(pos).shift()) * np.array(marketRet)：将移动后的持仓数据与每日收益率相乘，得到每个持仓在下一交易日的收益。\n# np.nansum(..., axis=1)：沿着行方向对收益进行求和，得到每个交易日的总收益。\n# ... / capital / holddays：将总收益除以初始资本（capital）和持仓天数（holddays），得到每日收益率。\nret=np.nansum(np.array(pd.DataFrame(pos).shift())*np.array(marketRet), axis=1)/capital/holddays\n# 夏普比率（Sharpe Ratio） \n# np.sqrt(len(ret))：计算观测值的数量的平方根，即 (\\sqrt{T})，其中 (T) 是观测值的数量。\n# np.nanmean(ret)：计算收益率的平均值，忽略NaN值。\n# np.nanstd(ret)：计算收益率的标准差，忽略NaN值。\n# 将上述三个值相除，得到夏普比率\nsharpe=np.sqrt(len(ret))*np.nanmean(ret)/np.nanstd(ret)\n\nprint(\"Gaussian Test statistic=%f\" % sharpe)\n#Gaussian Test statistic=2.769741\n\n# Randomized market returns hypothesis test\n# =============================================================================\n#_,_,mean,var,skew,kurt=describe(marketRet, nan_policy='omit')\n# =============================================================================\n\n# fit方法用于估计Pearson III分布的参数。\n# fit方法返回三个参数：skew_、loc_和scale_，分别表示：\n# skew_：偏度参数，描述了分布的不对称程度。正值表示右偏（尾部向右延伸），负值表示左偏（尾部向左延伸）。\n# `loc_**：**位置参数，描述了分布的中心位置。通常与均值相关。\n# `scale_**：**尺度参数，描述了分布的宽度或分散程度。通常与标准差相关。\nskew_, loc_, scale_=pearson3.fit(marketRet[1:]) # First element is NaN\nnumSampleAvgretBetterOrEqualObserved=0\nfor sample in range(100):\n    # rvs方法用于从指定的Pearson III分布中随机抽取样本。\n    # 以下是代码中各个参数的含义：\n    # skew_：偏度参数，描述了分布的不对称程度。\n    # loc_：位置参数，描述了分布的中心位置。\n    # scale_：尺度参数，描述了分布的宽度或分散程度。\n    # size：生成的模拟数据的大小，这里设置为与原始市场收益率数据（marketRet）相同的大小。\n    # random_state：随机数生成器的种子，用于确保每次运行代码时生成的随机数据相同。\n    marketRet_sim=pearson3.rvs(skew=skew_, loc=loc_, scale=scale_, size=marketRet.shape[0], random_state=sample)\n    cl_sim=np.cumproduct(1+marketRet_sim)-1\n    \n    longs_sim =cl_sim &gt; pd.Series(cl_sim).shift(lookback)\n    shorts_sim=cl_sim &lt; pd.Series(cl_sim).shift(lookback)\n    \n    pos_sim=np.zeros(cl_sim.shape[0])\n    \n    for h in range(0, holddays):\n        long_sim_lag=longs_sim.shift(h)\n        long_sim_lag[long_sim_lag.isna()]=False\n        long_sim_lag=long_sim_lag.astype(bool)\n    \n        short_sim_lag=shorts_sim.shift(h)\n        short_sim_lag[short_sim_lag.isna()]=False\n        short_sim_lag=short_sim_lag.astype(bool)\n    \n        pos_sim[long_sim_lag]=pos_sim[long_sim_lag]+1\n        pos_sim[short_sim_lag]=pos_sim[short_sim_lag]-1\n        \n        capital=np.nansum(np.array(pd.DataFrame(abs(pos_sim)).shift()), axis=1)\n        pos_sim[capital==0,]=0\n        capital[capital==0]=1\n               \n        ret_sim=np.nansum(np.array(pd.DataFrame(pos_sim).shift())*np.array(marketRet_sim), axis=1)/capital/holddays\n        if (np.mean(ret_sim) &gt;= np.mean(ret)):\n            numSampleAvgretBetterOrEqualObserved=numSampleAvgretBetterOrEqualObserved+1\n            \nprint(\"Randomized prices: p-value=%f\" % (numSampleAvgretBetterOrEqualObserved/100))\n#Randomized prices: p-value=23.617800\n\n# Randomized entry trades hypothesis test\nnumSampleAvgretBetterOrEqualObserved=0\nfor sample in range(100):\n    # 生成一个随机排列的索引数组\n    P=np.random.permutation(len(longs))\n    longs_sim=longs[P]\n    shorts_sim=shorts[P]\n    \n    pos_sim=np.zeros(cl_sim.shape[0])\n\n    for h in range(0, holddays):\n        long_sim_lag=longs_sim.shift(h)\n        long_sim_lag[long_sim_lag.isna()]=False\n        long_sim_lag=long_sim_lag.astype(bool)\n    \n        short_sim_lag=shorts_sim.shift(h)\n        short_sim_lag[short_sim_lag.isna()]=False\n        short_sim_lag=short_sim_lag.astype(bool)\n    \n        pos_sim[long_sim_lag]=pos_sim[long_sim_lag]+1\n        pos_sim[short_sim_lag]=pos_sim[short_sim_lag]-1\n        \n        capital=np.nansum(np.array(pd.DataFrame(abs(pos_sim)).shift()), axis=1)\n        pos_sim[capital==0,]=0\n        capital[capital==0]=1\n               \n        ret_sim=np.nansum(np.array(pd.DataFrame(pos_sim).shift())*np.array(marketRet), axis=1)/capital/holddays\n        if (np.mean(ret_sim) &gt;= np.mean(ret)):\n            numSampleAvgretBetterOrEqualObserved=numSampleAvgretBetterOrEqualObserved+1\n            \nprint(\"Randomized trades: p-value=%f\" % (numSampleAvgretBetterOrEqualObserved/100))\n#Randomized trades: p-value=1.365600\n\nGaussian Test statistic=2.769741\nRandomized prices: p-value=23.500000\nRandomized trades: p-value=1.000000\n\n\n\n#是的，Python 中有约翰森检验函数，即 scipy.stats.johnsonsu。\n# 该函数用于对连续型数据进行正态性检验，并返回约翰森变换后的参数。\n#以下是 scumpy.stats.johnsonsu 函数的基本用法示例：\n\nfrom scipy import stats\n\n# 假设有一组连续型数据\ndata = [1.2, 3.4, 5.6, 7.8, 9.0]\n\n# 对数据进行约翰森正态性检验\nresult = stats.johnsonsu.fit(data)\n\n# 输出约翰森变换后的参数\nprint(result)\n\n\n# 需要注意的是，约翰森检验函数适用于连续型数据的正态性检验，对于离散型数据或其他类型的数据可能不适用。\n\n(np.float64(9.932945657673585), np.float64(1.8845431800180394), np.float64(11.36217894129853), np.float64(0.05378935338333127))"
  },
  {
    "objectID": "posts/2024-07-27-Algorithmic-Trading.html#协整关系",
    "href": "posts/2024-07-27-Algorithmic-Trading.html#协整关系",
    "title": "算法交易：制胜策略与原理(欧内斯特·陈)之一",
    "section": "协整关系",
    "text": "协整关系\n协整关系（Cointegration）是时间序列分析中的一个重要概念，它描述了两个或多个非平稳时间序列之间存在的长期稳定关系。\n在经济学和金融学中，协整关系常用于分析不同经济变量之间的长期均衡关系。例如，协整关系可以用来检验两个经济指标（如价格和工资）是否长期同步变动，从而判断它们之间是否存在长期的均衡关系。\n协整关系的存在需要满足一定的条件，包括：\n\n变量的非平稳性：协整关系通常存在于非平稳的时间序列之间。如果所有变量都是平稳的，那么它们之间就不存在协整关系。\n长期稳定性：协整关系描述的是变量之间的长期稳定关系。即使短期内变量之间可能出现波动或偏离，但在长期内它们会回归到均衡状态。\n最小二乘法估计的有效性：在存在协整关系的情况下，可以使用最小二乘法（OLS）对回归模型进行估计，并且得到的估计量是一致的。\n\n协整关系的检验通常使用Engle-Granger两步法或其他更复杂的统计方法。如果检验结果表明变量之间存在协整关系，那么就可以进一步分析它们之间的长期均衡关系，并进行相关的预测和政策分析。"
  },
  {
    "objectID": "posts/2024-07-27-Algorithmic-Trading.html#卡尔曼滤波法则",
    "href": "posts/2024-07-27-Algorithmic-Trading.html#卡尔曼滤波法则",
    "title": "算法交易：制胜策略与原理(欧内斯特·陈)之一",
    "section": "卡尔曼滤波法则",
    "text": "卡尔曼滤波法则\n卡尔曼滤波法则是一种数学算法，用于估计和预测未知变量的值，特别是那些受到随机过程影响的系统。它是由匈牙利出生的美国工程师拉尔夫·伊万·卡尔曼在1960年发明的。卡尔曼滤波器的发展源于20世纪50年代末到60年代初的航天任务需求。当时需要一种能够实时处理复杂动态系统的测量数据的方法，以便进行精确导航和控制。卡尔曼滤波器正是在这种背景下应运而生，成为解决这些问题的有效工具。它的成功应用很快得到了广泛认可，并在之后的几十年里，在多个科学和工程领域中都得到了深入的研究和广泛应用。以下是关于卡尔曼滤波法则的相关信息：\n\n卡尔曼滤波的基本原理\n卡尔曼滤波的基本思想是通过观测数据对系统状态进行递归估计，不断更新状态的估计值。它假设系统状态是一个高斯分布，而观测值是由真实值和高斯噪声组成的。在每个时间步，卡尔曼滤波通过当前状态的预测和观测值的比较，得到一个新的状态估计值，并且利用上一个时间步的估计误差来调整预测误差的协方差矩阵，从而使得估计误差最小化。\n\n\n卡尔曼滤波的主要步骤\n\n预测步骤：根据上一时刻的状态估计和状态转移方程预测当前时刻的状态估计和协方差矩阵。\n更新步骤：根据当前时刻的观测值和观测方程，计算出当前时刻的状态估计和协方差矩阵。\n\n\n\n卡尔曼滤波的应用领域\n\n航天领域：飞船自主导航。\n自动驾驶车辆：高级驾驶辅助系统(ADAS)和自动驾驶车辆。\n机器人导航和运动控制：融合来自多种传感器的信息，包括激光雷达、视觉传感器和惯性测量单元(IMU)。\n医学影像处理：图像去噪和增强。\n金融领域：股票价格预测、风险管理以及利率模型的构建。\n\n通过上述分析，我们可以看到卡尔曼滤波法则不仅在理论上有着严谨的数学基础，而且在实际应用中也有着广泛的应用和重要的地位。"
  },
  {
    "objectID": "posts/2024-07-27-Algorithmic-Trading.html#布林带指标",
    "href": "posts/2024-07-27-Algorithmic-Trading.html#布林带指标",
    "title": "算法交易：制胜策略与原理(欧内斯特·陈)之一",
    "section": "布林带指标",
    "text": "布林带指标\n布林带指标（Bollinger Bands）是一种基于移动平均线和标准差计算的技术分析工具，用于判断价格的波动趋势和判断市场支撑和阻力位。它由三条线组成：中轨线（通常是20日移动平均线）、上轨线（中轨线加上两倍标准差）和下轨线（中轨线减去两倍标准差）。布林带指标通过这三条线描绘出价格波动的范围，帮助投资者判断市场是处于正常波动状态还是极端波动状态。以下是关于布林带指标的相关信息：\n\n布林带指标的原理\n布林带指标的原理基于统计学中的标准差原理，通过计算股票或其他资产价格的移动平均线（通常是20日移动平均线）和标准差来描绘价格波动的范围。上轨线和下轨线分别表示价格的标准差倍数，通常为2倍和-2倍，从而展示出价格在过去的20个交易日中，相对于其移动平均线的波动范围。\n\n\n布林带指标的使用方法\n\n基本用法：股价通常在布林通道区间内运行，股价运行到上轨附近时强压力位，一般可以作为卖点；股价运行到下轨附近是强支撑位，一般可以作为买点。\n与其他指标的配合使用：布林带指标可以与其他技术指标如成交量、KDJ指标等配合使用，以获得更准确的买卖信号。\n\n\n\n注意事项\n\n参数设定：布林线参数的设定不得小于6，静态钱龙设定值通常是10；动态钱龙设定时通常为20。\n市场环境：布林带指标适用于相对平稳的市场，当市场波动较大的时候，布林带指标提供的参考价值就不高了。\n确认信号：最好使用其他指标（如MACD、RSI）来确认布林带提供的信号，以避免误判。\n\n通过以上信息，投资者可以更好地理解和使用布林带指标，以提高股票交易的准确性和效率。\n\nimport altair as alt\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# 创建一个简单的数据集\ndata = pd.DataFrame({\n    'x': [1, 2, 3, 4, 5],\n    'y': [2, 4, 6, 8, 10]\n})\n\n# 创建一个散点图\nchart = alt.Chart(data).mark_circle().encode(\n    x='x:Q',\n    y='y:Q'\n)\n# 显示图表\n# chart.show()\nplt.plot(data)\nplt.show()\n\n\n\n\n\n\n\n\n\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport numpy as np\nplt.rcParams[\"font.sans-serif\"] = [\"SimHei\"] \nmpl.rcParams['axes.unicode_minus'] = False # 正常显示负号\n# zhfont=mpl.font_manager.FontProperties(fname=\"/System/Library/Fonts/PingFang.ttc\")\n# mpl.rcParams['axes.unicode_minus'] = False\nx=np.linspace(-np.pi,np.pi,100)\ny=np.sin(x)\nplt.title(u'正弦函数')\nplt.plot(x,y)\n\nplt.show()\n\n\n\n\n\n\n\n\n\n# import altair with an abbreviated alias\nimport altair as alt\n# print(alt.Config)\n\n# alt.renderers.set_embed_options(base_url='js/',vega_url='js/vega@5',\n# vega_lite_url='js/vega-lite@4',\n# vega_embed_url='js/vega-embed@6')\n# 算了吧太费劲了，放弃altair\n# alt.renderers.enable('html', base_url='js')\n\n# load a sample dataset as a pandas DataFrame\nfrom vega_datasets import data\ncars = data.cars()\n# alt.renderers.enable('html', vega_cdn='https://cdnjs.cloudflare.com/libraries/vega', vega_lite_cdn='https://cdnjs.cloudflare.com/libraries/vega-lite')\n# https://cdnjs.cloudflare.com/ajax/libs/vega-embed/6.26.0/vega-embed.min.js\n# make the chart\nalt.Chart(cars).mark_point().encode(\n    x='Horsepower',\n    y='Miles_per_Gallon',\n    color='Origin',\n).interactive()"
  },
  {
    "objectID": "posts/2021-08-27-special-topics-in-quantitative-trading.html",
    "href": "posts/2021-08-27-special-topics-in-quantitative-trading.html",
    "title": "CH7-量化交易专题",
    "section": "",
    "text": "只有当证券价格是均值回归的或趋势的，交易策略才能盈利。否则，价格是随机漫步的，交易将无利可图。 如果你相信价格是均值回归的，并且目前相对较低，应当现在买入，并准备在以后价格升高时卖出。但是，如果你相信价格是趋势的，且目前处于低位，应当现在卖出，并准备在以后价格更低时买入。价格处于高位则刚好相反。\n学术研究表明，股票价格“一般而言”非常接近随机漫步。但这并不意味着在特殊条件下价格不会表现出一定程度的均值回归或趋势行为。"
  },
  {
    "objectID": "posts/2021-08-27-special-topics-in-quantitative-trading.html#均值回归策略和惯性策略",
    "href": "posts/2021-08-27-special-topics-in-quantitative-trading.html#均值回归策略和惯性策略",
    "title": "CH7-量化交易专题",
    "section": "",
    "text": "只有当证券价格是均值回归的或趋势的，交易策略才能盈利。否则，价格是随机漫步的，交易将无利可图。 如果你相信价格是均值回归的，并且目前相对较低，应当现在买入，并准备在以后价格升高时卖出。但是，如果你相信价格是趋势的，且目前处于低位，应当现在卖出，并准备在以后价格更低时买入。价格处于高位则刚好相反。\n学术研究表明，股票价格“一般而言”非常接近随机漫步。但这并不意味着在特殊条件下价格不会表现出一定程度的均值回归或趋势行为。"
  },
  {
    "objectID": "posts/2021-08-27-special-topics-in-quantitative-trading.html#状态转换",
    "href": "posts/2021-08-27-special-topics-in-quantitative-trading.html#状态转换",
    "title": "CH7-量化交易专题",
    "section": "状态转换",
    "text": "状态转换\n状态是金融市场中一个最基本的概念。如果没有状态，何来“牛市”和“熊市”？自金融市场诞生之日起，人们就试图预测状态转换，即寻找所谓的“拐点”。\n其他最常见的金融或经济状态研究，包括通货膨胀与经济衰退状态、高波动率与低波动率状态以及均值回归与趋势状态。其中，波动率状态转换似乎最实用经典计量经济学工具，如广义自回归条件异方差（GARCH）模型。\n学术界一般沿用以下思路对股票价格的状态转换进行建模：\n\n假设价格在两个（或多个）状态上的概率分布不同。最简单的情况，两个状态的价格都服从对数正态分布，但均值和（或）标准差不同。\n假设状态之间存在某种转移概率\n使用诸如最大似然估计这样的标准统计方法，通过拟合历史数据，来确定状态概率分布和转移概率的参数。\n根据上述拟合模型，找出下一个时间步长的期望状态，更重要的，找出股票的期望价格。\n\n这种方法通常被称为“马尔科夫状态转换模型”或“隐马尔科夫模型”，这一模型通常基于贝叶斯概率框架。\n虽然理论框架完美，马尔科夫状态转换模型在实际交易中的用途却不大。这是因为模型假设状态之间的转移概率都是固定的。实际应用中，这意味着在任何时候股票从正常的静止状态转移到不稳定状态的概率非常小。而这对于想知道转移概率在何时（以及何种情况下）突然达到峰值的交易员，是完全没有用的。这就需要用到拐点模型。\n拐点模型使用了数据挖掘方法：输入所有可能预测拐点或状态转换的变量。变量包括当前的波动率、最近一期的收益，以及消费者信心指数、石油价格变化、债券价格变化等宏观经济数据的变化。"
  },
  {
    "objectID": "posts/2021-08-27-special-topics-in-quantitative-trading.html#平稳性和协整性",
    "href": "posts/2021-08-27-special-topics-in-quantitative-trading.html#平稳性和协整性",
    "title": "CH7-量化交易专题",
    "section": "平稳性和协整性",
    "text": "平稳性和协整性\n如果一个时间序列不会越来越大地偏离初始值，这个时间序列就是“平稳的”。用专业术语来说，平稳的时间序列就是“零阶自积”的，即I(0)。不过，大多数股票的价格序列都是不平稳的，通常表现为几何随机游走，不断地离出事点（如首次公开发行价）价值越来越远。尽管如此，你能找到像买入一只股票、卖出一只股票这样的股票配对，配对的市场价值是平稳的。这种情况下，两个独立的时间序列被称为“协整”。协整配对中的两个股票来自同一行业。\n检测两个价格序列是否协整，如何找到最优的对冲比率。 协整检验的主要方法是ADF检验。\n如果一个价格序列（可以是一只股票、一对股票或是一个投资组合）是平稳的，只要未来继续保持平稳（这未必能保证），采用均值回归策略一定能盈利。"
  },
  {
    "objectID": "posts/2021-08-27-special-topics-in-quantitative-trading.html#因子模型",
    "href": "posts/2021-08-27-special-topics-in-quantitative-trading.html#因子模型",
    "title": "CH7-量化交易专题",
    "section": "因子模型",
    "text": "因子模型\n因子收益率是股票收益率的共同驱动因素，与单个股票无关。\n因子风险表示对哥哥共同驱动因素的敏感度。\n所有不能用共同因子解释的收益部分就是特有收益率。（比如，仅与某只股票相关，可以看做是APT模型中的随机噪音部分）"
  },
  {
    "objectID": "posts/2021-08-27-special-topics-in-quantitative-trading.html#清仓策略",
    "href": "posts/2021-08-27-special-topics-in-quantitative-trading.html#清仓策略",
    "title": "CH7-量化交易专题",
    "section": "清仓策略",
    "text": "清仓策略\n\n固定的持有期\n目标价格或盈利上限\n最新的建仓信号\n止损价格"
  },
  {
    "objectID": "posts/2021-08-27-special-topics-in-quantitative-trading.html#季节性交易策略",
    "href": "posts/2021-08-27-special-topics-in-quantitative-trading.html#季节性交易策略",
    "title": "CH7-量化交易专题",
    "section": "季节性交易策略",
    "text": "季节性交易策略"
  },
  {
    "objectID": "posts/2021-08-27-special-topics-in-quantitative-trading.html#高频交易策略",
    "href": "posts/2021-08-27-special-topics-in-quantitative-trading.html#高频交易策略",
    "title": "CH7-量化交易专题",
    "section": "高频交易策略",
    "text": "高频交易策略\n高频交易策略能获得高夏普比率的理由很简单：根据大数定律，交易的次数越多，收益率相对于均值的偏差就越小。而在高频交易策略下，一天可交易成百上千次。（这交易佣金也会很高啊）"
  },
  {
    "objectID": "posts/2024-08-21-conceptions-in-algorithmic-trading.html",
    "href": "posts/2024-08-21-conceptions-in-algorithmic-trading.html",
    "title": "算法交易中的一些概念",
    "section": "",
    "text": "高斯分布，也称为正态分布，是一种在自然界和社会科学中广泛存在的概率分布。它以数学家卡尔·弗里德里希·高斯的名字命名，因其图形呈钟形曲线而得名“钟形曲线”。以下是详细介绍：\n高斯分布的基本原理\n定义：高斯分布是一种连续概率分布，其图形显示为对称于平均值的钟形曲线。\n数学表达：若随机变量X服从数学期望为μ、方差为σ²的正态分布，记为N(μ，σ²)。\n应用领域：高斯分布在自然科学、工程学和社会科学等领域中广泛应用，用于描述连续型的随机变量。\n高斯分布的特性\n对称性：分布曲线关于平均值μ对称。\n集中性：大部分数据集中在平均值附近，离平均值越远，数据出现的概率越低。\n数学特性：高斯分布的曲线由均值μ和标准差σ决定，其中标准差σ越小，分布越集中；σ越大，分布越分散。\n高斯分布的应用\n统计学：在统计学中，高斯分布是描述连续型随机变量的重要工具，如测量误差分析。\n机器学习：作为许多机器学习算法（如线性回归、聚类分析）的基础假设。\n金融领域：用于风险评估和资产定价。\n图像处理：在图像处理中，高斯分布用于噪声模型和图像平滑。\n自然和社会现象：高斯分布在描述人口智力、身高、体重等自然和社会现象中无处不在。"
  },
  {
    "objectID": "posts/2024-08-21-conceptions-in-algorithmic-trading.html#高斯分布",
    "href": "posts/2024-08-21-conceptions-in-algorithmic-trading.html#高斯分布",
    "title": "算法交易中的一些概念",
    "section": "",
    "text": "高斯分布，也称为正态分布，是一种在自然界和社会科学中广泛存在的概率分布。它以数学家卡尔·弗里德里希·高斯的名字命名，因其图形呈钟形曲线而得名“钟形曲线”。以下是详细介绍：\n高斯分布的基本原理\n定义：高斯分布是一种连续概率分布，其图形显示为对称于平均值的钟形曲线。\n数学表达：若随机变量X服从数学期望为μ、方差为σ²的正态分布，记为N(μ，σ²)。\n应用领域：高斯分布在自然科学、工程学和社会科学等领域中广泛应用，用于描述连续型的随机变量。\n高斯分布的特性\n对称性：分布曲线关于平均值μ对称。\n集中性：大部分数据集中在平均值附近，离平均值越远，数据出现的概率越低。\n数学特性：高斯分布的曲线由均值μ和标准差σ决定，其中标准差σ越小，分布越集中；σ越大，分布越分散。\n高斯分布的应用\n统计学：在统计学中，高斯分布是描述连续型随机变量的重要工具，如测量误差分析。\n机器学习：作为许多机器学习算法（如线性回归、聚类分析）的基础假设。\n金融领域：用于风险评估和资产定价。\n图像处理：在图像处理中，高斯分布用于噪声模型和图像平滑。\n自然和社会现象：高斯分布在描述人口智力、身高、体重等自然和社会现象中无处不在。"
  },
  {
    "objectID": "posts/2024-08-21-conceptions-in-algorithmic-trading.html#学生t分布",
    "href": "posts/2024-08-21-conceptions-in-algorithmic-trading.html#学生t分布",
    "title": "算法交易中的一些概念",
    "section": "学生t分布",
    "text": "学生t分布\n学生t分布，也称为Student’s t-distribution，是一种连续概率分布，它在统计学中特别重要，尤其是在小样本情况下估计呈正态分布且标准差未知的总体均值时。以下是关于学生t分布理论的详细介绍：\n\n学生t分布的由来\n学生t分布最早由英国统计学家威廉·塞弗顿(William Sealy Gosset)在1908年提出，当时他使用笔名“学生”发表了自己的研究成果。Gosset的工作是在酿酒厂进行的，他需要分析小样本数据，因此开发了t分布来解决小样本量下的统计问题。\n\n\n学生t分布的定义\nt分布的概率密度函数(PDF)定义为：\n\\[f(t) = \\frac{\\Gamma\\left(\\frac{v+1}{2}\\right)}{\\sqrt{v\\pi}}\\left(1+\\frac{t^2}{v}\\right)^{-\\frac{v+1}{2}}\\]\n其中，\\(v\\) 是自由度，是一个正整数。\n\n\n学生t分布的性质\n\n对称性：t分布以0为中心，左右对称。\n自由度的影响：自由度越大，t分布的形状越接近于标准正态分布，尾部越窄；自由度越小，尾部越厚，形状更加扁平。\n应用：t分布广泛应用于统计学中的假设检验和置信区间估计，特别是在小样本情况下。\n\n\n\n学生t分布与正态分布的关系\n当样本量足够大时，样本平均数的分布可以转化为标准正态分布。但是当样本量较小时，这个比值的分布不再是标准正态分布，而是t分布。\n\n\n学生t分布的自由度\n自由度(degrees of freedom, df)是一个参数，用来确定t分布的形状。它通常与样本量有关，但并不等于样本量。在不同的统计问题中，自由度的计算方式略有不同，但它们都与样本量和统计模型的复杂度有关。\n通过了解学生t分布的基本原理、定义、性质及其与正态分布的关系，可以更好地应用这一理论于实际的统计分析和研究中。"
  },
  {
    "objectID": "posts/2024-08-21-conceptions-in-algorithmic-trading.html#帕累托分布",
    "href": "posts/2024-08-21-conceptions-in-algorithmic-trading.html#帕累托分布",
    "title": "算法交易中的一些概念",
    "section": "帕累托分布",
    "text": "帕累托分布\n帕累托分布理论，也称为帕累托法则或80/20法则，是由意大利经济学家维弗雷多·帕雷托提出的。这一理论指出，在许多情况下，大约80%的结果来自于20%的原因。这一原则不仅在经济学中有广泛应用，也被应用于社会学、管理学等多个领域。以下是关于帕累托分布理论的详细介绍：\n\n帕累托分布的定义和原理\n帕累托分布是一种幂次定律分布，描述了在许多情况下，一小部分原因会导致大部分结果的现象。例如，20%的人口可能拥有80%的财富，或者20%的客户可能贡献80%的销售额。\n\n\n帕累托分布的应用实例\n\n销售领域：识别并专注于最重要的20%的客户，以增加销售额。\n时间管理：优先处理能带来最大效益的20%的关键任务。\n商品库存管理：对贡献80%销售额的20%的商品给予更多关注。\n生产质量控制：集中解决导致80%客户投诉的20%的缺陷问题。\n健身锻炼：专注于对身体产生80%锻炼效果的20%的关键动作。\n软件开发：优先修复导致80%错误的20%的关键代码。\n\n\n\n帕累托分布的数学表达\n帕累托分布的概率密度函数(PDF)通常表示为：\n\\[f(x) = \\frac{k \\cdot x^{-\\alpha}}{1 - x^{-\\alpha}}\\]\n其中，\\(x\\) 是大于某个最小值 \\(x_{min}\\) 的正数，\\(k\\) 是分布的尺度参数，而 \\(\\alpha\\) 是形状参数，决定了分布的形状。当 \\(\\alpha &gt; 1\\) 时，分布是长尾的，这在描述财富分布等自然和社会现象时非常有用。\n\n\n帕累托分布与正态分布的区别\n\n形状：帕累托分布是长尾的，而正态分布是钟形的。\n应用领域：帕累托分布常用于描述极端值分布，如财富分布，而正态分布则适用于描述大多数自然和社会现象中的连续变量。\n\n通过了解帕累托分布的基本原理、定义、性质及其与正态分布的区别，可以更好地应用这一理论于实际的统计分析和研究中。帕累托分布不仅是一个数学工具，更是一种理解和分析复杂系统的思维方式。"
  },
  {
    "objectID": "posts/2024-08-21-conceptions-in-algorithmic-trading.html#乌伦贝克随机微分方程",
    "href": "posts/2024-08-21-conceptions-in-algorithmic-trading.html#乌伦贝克随机微分方程",
    "title": "算法交易中的一些概念",
    "section": "乌伦贝克随机微分方程",
    "text": "乌伦贝克随机微分方程\n乌伦贝克（Uhlenbeck）随机微分方程是一类重要的随机微分方程，通常用于描述物理、金融等领域中的随机现象。这类方程通常具有以下形式：\n\\[\ndX_t = b(X_t)dt + \\sigma(X_t)dW_t\n\\]\n其中，\\(X_t\\) 是一个随机过程，\\(b(X_t)\\) 是漂移项，\\(\\sigma(X_t)\\) 是扩散项，\\(W_t\\) 是一个标准布朗运动。\n乌伦贝克随机微分方程的一个特殊情况是奥恩斯坦-乌伦贝克（Ornstein-Uhlenbeck）过程，其形式如下：\n\\[\ndX_t = -\\theta X_t dt + \\sigma dW_t\n\\]\n其中，\\(\\theta\\) 和 \\(\\sigma\\) 是常数。这个过程描述了一个随机变量在受到线性恢复力和随机扰动的影响下的演化。\n解乌伦贝克随机微分方程通常需要使用随机微积分的理论和技术。对于一般的乌伦贝克随机微分方程，可以使用伊藤公式（Ito’s lemma）来求解。对于奥恩斯坦-乌伦贝克过程，可以直接求解得到其解析解：\n\\[\nX_t = X_0 e^{-\\theta t} + \\sigma \\int_0^t e^{-\\theta (t-s)} dW_s\n\\]\n其中，\\(X_0\\) 是初始条件。\n在实际应用中，乌伦贝克随机微分方程被广泛用于模拟和分析各种随机现象，如金融市场的波动、物理系统的布朗运动等。"
  },
  {
    "objectID": "posts/2024-08-21-conceptions-in-algorithmic-trading.html#均值标准差偏度和峰度",
    "href": "posts/2024-08-21-conceptions-in-algorithmic-trading.html#均值标准差偏度和峰度",
    "title": "算法交易中的一些概念",
    "section": "均值、标准差、偏度和峰度",
    "text": "均值、标准差、偏度和峰度\n均值、标准差、偏度和峰度是统计学中用于描述数据分布特征的四个重要指标。\n\n均值（Mean）：\n\n定义：所有数据的总和除以数据的个数。\n计算公式：μ = (Σx_i) / n，其中 x_i 是每个数据点，n 是数据点的数量。\n意义：均值反映了数据的集中趋势，即数据的一般水平。\n\n标准差（Standard Deviation）：\n\n定义：衡量数据点相对于均值的离散程度。\n计算公式：σ = sqrt(Σ(x_i - μ)^2 / n)，其中 x_i 是每个数据点，μ 是均值，n 是数据点的数量。\n意义：标准差越大，数据越分散；标准差越小，数据越集中。\n\n偏度（Skewness）：\n\n定义：衡量数据分布的对称性。\n计算公式：Sk = (Σ(x_i - μ)^3 / n) / σ^3，其中 x_i 是每个数据点，μ 是均值，σ 是标准差，n 是数据点的数量。\n意义：偏度为正表示数据右偏（尾部向右延伸），偏度为负表示数据左偏（尾部向左延伸），偏度为0表示数据对称。\n\n峰度（Kurtosis）：\n\n定义：衡量数据分布的尖峭程度。\n计算公式：K = (Σ(x_i - μ)^4 / n) / σ^4 - 3，其中 x_i 是每个数据点，μ 是均值，σ 是标准差，n 是数据点的数量。\n意义：峰度大于3表示数据分布比正态分布更尖峭，峰度小于3表示数据分布比正态分布更平坦。\n\n\n这些指标可以帮助我们更好地理解数据的分布特征，从而做出更合理的分析和决策。"
  },
  {
    "objectID": "posts/2024-08-21-conceptions-in-algorithmic-trading.html#皮尔逊分布",
    "href": "posts/2024-08-21-conceptions-in-algorithmic-trading.html#皮尔逊分布",
    "title": "算法交易中的一些概念",
    "section": "皮尔逊分布",
    "text": "皮尔逊分布\n皮尔逊分布，也称为皮尔逊III型分布，是一种连续概率分布，常用于统计学中描述偏态分布的数据。它是由Karl Pearson在19世纪提出的，作为一种更一般化的分布，用于描述那些不符合正态分布假设的数据。以下是关于皮尔逊分布的相关信息：\n\n定义\n皮尔逊分布的概率密度函数为：\n[ f(x, ) = ((x - ))^{- 1} (-(x - )) ]\n其中：\n\n\\(\\beta = \\frac{2}{\\kappa}\\)\n\\(\\alpha = \\beta^2 = \\frac{4}{\\kappa^2}\\)\n\\(\\zeta = -\\frac{\\alpha}{\\beta} = -\\beta\\)\n\n这个概率密度函数在“标准化”形式下定义，通过loc和scale参数可以移动和/或缩放分布。\n\n\nScipy中的实现\n在Python的SciPy库中，可以通过scipy.stats.pearson3对象来生成Pearson III分布的随机变量、计算概率密度函数、累积分布函数(CDF)、逆累积分布函数(PPF)等。例如，生成随机数或显示概率密度函数的代码示例如下：\nimport numpy as np\nfrom scipy.stats import pearson3\n\n# 生成1000个随机数\nr = pearson3.rvs(skew=-2, size=1000)\n\n# 显示概率密度函数\nx = np.linspace(pearson3.ppf(0.01, skew=-2), pearson3.ppf(0.99, skew=-2), 100)\nplt.plot(x, pearson3.pdf(x, skew=-2), label='pearson3 pdf')\n通过这些工具，研究者可以更好地理解和分析偏态分布的数据，以及进行相关的统计推断和预测。\n\n\n应用场景\n皮尔逊III型分布适用于偏态分布数据的描述，特别是在统计学、金融、经济学等领域中，当数据分布明显偏离正态分布时，Pearson III分布提供了一个有效的模型来分析和预测数据。\n通过上述信息，可以看出皮尔逊分布在统计学和相关领域中具有重要的应用价值。"
  },
  {
    "objectID": "posts/2021-08-13-fishing-of-ideas.html",
    "href": "posts/2021-08-13-fishing-of-ideas.html",
    "title": "CH2-捕获点子",
    "section": "",
    "text": "This is the surprise: Finding a trading idea is actually not the hardest part of building a quantitative trading business. There are hundreds, if not thousands, of trading ideas that are in the public sphere at any time, accessible to anyone at little or no cost. Many authors of these trading ideas will tell you their complete methodologies in addition to their backtest results. There are finance and investment books, newspapers and magazines, main\u0002stream media web sites, academic papers vailable online or in the nearest public library, trader forums, blogs, and on and on.\n\n你可能会奇怪：寻找交易点子不是建立量化交易事业最难的部分。在公共领域有成千上万的交易点子，任何个人任何时间都可以免费或者用一点点花费就能获取到。很多交易点子的作者，不仅会完全告诉你实现的方法，还会附上他们的回测结果。有很多金融投资的书籍，报纸，杂志，主流媒体的网站，在线的学术期刊，或者最近的公共图书馆，交易者论坛，博客等等。\n\n\n\n类型\n网址\n\n\n\n\nAcademic\n\n\n\nBusiness schools’ finance professors’ websites\nwww.hbs.edu/research/research.html\n\n\nSocial Science Research Network\nwww.ssrn.com\n\n\nNational Bureau of Economic Research\nwww.nber.org\n\n\nBusiness schools’ quantitative finance seminars\nwww.ieor.columbia.edu/seminars/financialengineering\n\n\nButtonwood column in the Economist magazine’s finance section\nwww.economist.com\n\n\nFinancial web sites and blogs\n\n\n\nYahoo! Finance\nfinance.yahoo.com\n\n\nTradingMarkets\nwww.TradingMarkets.com\n\n\nSeeking Alpha\nwww.SeekingAlpha.com\n\n\nTheStreet.com\nwww.TheStreet.com\n\n\nThe Kirk Report\nwww.TheKirkReport.com\n\n\nAlea Blog\nwww.aleablog.com\n\n\nAbnormal Returns\nwww.AbnormalReturns.com\n\n\nBrett Steenbarger Trading Psychology\nwww.brettsteenbarger.com\n\n\n本书作者\nepchan.blogspot.com\n\n\nTrader forums\n\n\n\nElite Trader\nwww.Elitetrader.com\n\n\nWealth-Lab\nwww.wealth-lab.com\n\n\nNewspaper and magazines\n\n\n\nStocks, Futures and Options magazine\nwww.sfomag.com\n\n\n\n\nNo, the difficulty is not the lack of ideas. The difficulty is to develop a taste for which strategy is suitable for your personal circumstances and goals, and which ones look viable even before you devote the time to diligently backtest them. This taste for prospective strategies is what I will try to convey in this chapter.\n\n困难不是缺少点子。困难是培养出一种敏锐的嗅觉，能分辨出哪些策略是适合你的环境和目标的，并能在对策略进行回测前发觉其是否可行。这种预见策略的嗅觉正是我要在本章试图阐明的。"
  },
  {
    "objectID": "posts/2021-08-13-fishing-of-ideas.html#从何处获取策略",
    "href": "posts/2021-08-13-fishing-of-ideas.html#从何处获取策略",
    "title": "CH2-捕获点子",
    "section": "",
    "text": "This is the surprise: Finding a trading idea is actually not the hardest part of building a quantitative trading business. There are hundreds, if not thousands, of trading ideas that are in the public sphere at any time, accessible to anyone at little or no cost. Many authors of these trading ideas will tell you their complete methodologies in addition to their backtest results. There are finance and investment books, newspapers and magazines, main\u0002stream media web sites, academic papers vailable online or in the nearest public library, trader forums, blogs, and on and on.\n\n你可能会奇怪：寻找交易点子不是建立量化交易事业最难的部分。在公共领域有成千上万的交易点子，任何个人任何时间都可以免费或者用一点点花费就能获取到。很多交易点子的作者，不仅会完全告诉你实现的方法，还会附上他们的回测结果。有很多金融投资的书籍，报纸，杂志，主流媒体的网站，在线的学术期刊，或者最近的公共图书馆，交易者论坛，博客等等。\n\n\n\n类型\n网址\n\n\n\n\nAcademic\n\n\n\nBusiness schools’ finance professors’ websites\nwww.hbs.edu/research/research.html\n\n\nSocial Science Research Network\nwww.ssrn.com\n\n\nNational Bureau of Economic Research\nwww.nber.org\n\n\nBusiness schools’ quantitative finance seminars\nwww.ieor.columbia.edu/seminars/financialengineering\n\n\nButtonwood column in the Economist magazine’s finance section\nwww.economist.com\n\n\nFinancial web sites and blogs\n\n\n\nYahoo! Finance\nfinance.yahoo.com\n\n\nTradingMarkets\nwww.TradingMarkets.com\n\n\nSeeking Alpha\nwww.SeekingAlpha.com\n\n\nTheStreet.com\nwww.TheStreet.com\n\n\nThe Kirk Report\nwww.TheKirkReport.com\n\n\nAlea Blog\nwww.aleablog.com\n\n\nAbnormal Returns\nwww.AbnormalReturns.com\n\n\nBrett Steenbarger Trading Psychology\nwww.brettsteenbarger.com\n\n\n本书作者\nepchan.blogspot.com\n\n\nTrader forums\n\n\n\nElite Trader\nwww.Elitetrader.com\n\n\nWealth-Lab\nwww.wealth-lab.com\n\n\nNewspaper and magazines\n\n\n\nStocks, Futures and Options magazine\nwww.sfomag.com\n\n\n\n\nNo, the difficulty is not the lack of ideas. The difficulty is to develop a taste for which strategy is suitable for your personal circumstances and goals, and which ones look viable even before you devote the time to diligently backtest them. This taste for prospective strategies is what I will try to convey in this chapter.\n\n困难不是缺少点子。困难是培养出一种敏锐的嗅觉，能分辨出哪些策略是适合你的环境和目标的，并能在对策略进行回测前发觉其是否可行。这种预见策略的嗅觉正是我要在本章试图阐明的。"
  },
  {
    "objectID": "posts/2021-08-13-fishing-of-ideas.html#如何辨别策略是否适合你",
    "href": "posts/2021-08-13-fishing-of-ideas.html#如何辨别策略是否适合你",
    "title": "CH2-捕获点子",
    "section": "如何辨别策略是否适合你",
    "text": "如何辨别策略是否适合你\n有如下几个评判依据： * 你的工作时间 * 你的编程技能 * 你的交易资本 * 你的目标"
  },
  {
    "objectID": "posts/2021-08-13-fishing-of-ideas.html#识别可用的策略及其陷阱",
    "href": "posts/2021-08-13-fishing-of-ideas.html#识别可用的策略及其陷阱",
    "title": "CH2-捕获点子",
    "section": "识别可用的策略及其陷阱",
    "text": "识别可用的策略及其陷阱\n用这些方法快测试策略，确保你不会浪费你的时间和金钱\n\n这个策略和基准比较表现如何?它的回报有多持久? &gt; Though a strategy may have the same average return as the benchmark, perhaps it delivered positive returns every month while the benchmark occasionally suffered some very bad months. In this case, we would still deem the strategy superior. This leads us to consider the information ratio or Sharpe ratio (Sharpe,1994), rather than returns, as the proper performance measurement of a quantitative trading strategy.\n\n虽让一个策略可能和基准有相同的回报，但在基准下跌的月份里它仍然有正收益。我们仍然认为这个策略是优越的。这促使我们考虑用信息比率或者夏普比率，而不是回报来，作为衡量量化交易策略业绩的指标。\n\n$ Information Ratio = $\n\n$ 信息比率 = $\n(其中：超额收益率 = 组合收益率 - 基准收益率)\n\nAs a rule of thumb, any strategy that has a Sharpe ratio of less than 1 is not suitable as a stand-alone strategy. For a strategy that achieves profitability almost every month, its (annualized) Sharpe ratio is typically greater than 2. For a strategy that is profitable al\u0002most every day, its Sharpe ratio is usually greater than 3.\n\n一般来说，任何夏普率小于1的策略不适合作为单独策略。对于每月都有收益的策略，它的年化夏普率通常大于2.对于每天有收益的策略，他的夏普率通常大于3.\n\n下挫有多深多久？\n\n你要问自己，你能承受多深多久的下挫而不清算你的投资组合关闭你的策略。\n\n交易成本如何影响策略？\n\n交易成本不仅包括券商收取的佣金，还有流动成本和机会成本。\n\n数据是否存在生存者偏差\n\n历史数据库中的股票报价不包含破产退市的股票。\n\n为什么策略的业绩过几年会发生改变？\n\n策略回测要关注近几年的表现，久远的数据会包含交易成本和幸存者偏差的影响。\n\n策略是否收到数据范围偏差影响？\n\n策略含有过多参数可能会对历史数据产生过度拟合。\n\n策略是否在基金经理的盲区\n\n\nyou should look for those strategies that fly under the radar of most institutional investors, for example, strategies that have very low capacities because they trade too often, strategies that trade very few stocks ev\u0002ery day, or strategies that have very infrequent positions.\n\n你应该去寻找被机构投资者忽视的策略，比如，交易频繁容量很低的策略，每天只交易很少股票的策略，持仓时段稀少的策略。这样的特色策觉才有利可图，因为他们还没有完全被巨型的对冲基金套利掉。"
  },
  {
    "objectID": "posts/2021-08-19-executions-systems.html",
    "href": "posts/2021-08-19-executions-systems.html",
    "title": "CH5-交易执行系统",
    "section": "",
    "text": "An automated trading system will retrieve up-to-date market data from your brokerage or other data vendors, run a trading algorithm to generate orders, and submit those orders to your brokerage for execution.\n\n自动交易系统从经纪商或其他供应商获取市场数据，运行交易算法形成指令，提交指令给经纪商执行。\n全自动交易系统代价高昂，对于低频量化交易策略，半自动交易系统即可。\n\n半自动交易系统\n全自动交易系统"
  },
  {
    "objectID": "posts/2021-08-19-executions-systems.html#自动交易系统能为你做什么",
    "href": "posts/2021-08-19-executions-systems.html#自动交易系统能为你做什么",
    "title": "CH5-交易执行系统",
    "section": "",
    "text": "An automated trading system will retrieve up-to-date market data from your brokerage or other data vendors, run a trading algorithm to generate orders, and submit those orders to your brokerage for execution.\n\n自动交易系统从经纪商或其他供应商获取市场数据，运行交易算法形成指令，提交指令给经纪商执行。\n全自动交易系统代价高昂，对于低频量化交易策略，半自动交易系统即可。\n\n半自动交易系统\n全自动交易系统"
  },
  {
    "objectID": "posts/2021-08-19-executions-systems.html#雇佣编程顾问",
    "href": "posts/2021-08-19-executions-systems.html#雇佣编程顾问",
    "title": "CH5-交易执行系统",
    "section": "雇佣编程顾问",
    "text": "雇佣编程顾问\n这里有个策略保密的问题，其他的讨论不值一提，但是有个方法挺好的，就是把策略拆分雇佣不同的程序员，没人实现一部分，最后再合并。"
  },
  {
    "objectID": "posts/2021-08-19-executions-systems.html#最小化交易成本",
    "href": "posts/2021-08-19-executions-systems.html#最小化交易成本",
    "title": "CH5-交易执行系统",
    "section": "最小化交易成本",
    "text": "最小化交易成本\n\n可以通过避免交易低价股票来降低佣金\n根据股票的流动性来限制指令规模以减小市场冲击成本。警惕成交量小的股票，购买量不要超过其每日成交量的1%。\n根据股票市值来调整下单量也是减少市场冲击的方法\n但是不要按线性比率来调整下单量，因为公司市值差别巨大，按照固定比例会让下公司的下单量为0\n如果是超大单，分批次下单，以减少市场冲击。独立交易者通常不需要。"
  },
  {
    "objectID": "posts/2021-08-19-executions-systems.html#用仿真交易测试交易系统",
    "href": "posts/2021-08-19-executions-systems.html#用仿真交易测试交易系统",
    "title": "CH5-交易执行系统",
    "section": "用仿真交易测试交易系统",
    "text": "用仿真交易测试交易系统"
  },
  {
    "objectID": "posts/2021-08-19-executions-systems.html#为什么实际业绩偏离预期",
    "href": "posts/2021-08-19-executions-systems.html#为什么实际业绩偏离预期",
    "title": "CH5-交易执行系统",
    "section": "为什么实际业绩偏离预期",
    "text": "为什么实际业绩偏离预期\n\n自动交易软件是否有bug\n自动交易系统产生的交易和回测程序产生的交易是否一致\n交易成本是否比预期的高很多\n是否交易了流动性差的股票产生了市场冲击\n数据迁就偏差\n状态变更影响，市场结构和宏观经济环境发生巨变"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "关于",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "王君敕的炼丹房",
    "section": "",
    "text": "算法交易：制胜策略与原理(欧内斯特·陈)之二\n\n\n\n\n\n\n量化交易\n\n\n\n\n\n\n\n\n\nAug 22, 2024\n\n\n王一刀\n\n\n\n\n\n\n\n\n\n\n\n\n算法交易中的一些概念\n\n\n\n\n\n\n量化交易\n\n\n\n\n\n\n\n\n\nAug 21, 2024\n\n\n王君敕\n\n\n\n\n\n\n\n\n\n\n\n\n关于迪基-富勒检验\n\n\n\n\n\n\n量化交易\n\n\n\n\n\n\n\n\n\nAug 20, 2024\n\n\n王一刀\n\n\n\n\n\n\n\n\n\n\n\n\n算法交易：制胜策略与原理(欧内斯特·陈)之一\n\n\n\n\n\n\n量化交易\n\n\n\n\n\n\n\n\n\nJul 27, 2024\n\n\n王一刀\n\n\n\n\n\n\n\n\n\n\n\n\n随机漫步\n\n\n\n\n\n\n量化交易\n\n\n\n\n\n\n\n\n\nJul 25, 2024\n\n\n王一刀\n\n\n\n\n\n\n\n\n\n\n\n\nbacktrader回测系统\n\n\n\n\n\n\n量化交易\n\n\n\nbacktrader\n\n\n\n\n\nDec 6, 2021\n\n\n王一刀\n\n\n\n\n\n\n\n\n\n\n\n\nCH6-资金和风险管理\n\n\n\n\n\n\n量化交易\n\n\n\nMoney and Risk Management\n\n\n\n\n\nAug 27, 2021\n\n\n王一刀\n\n\n\n\n\n\n\n\n\n\n\n\nCH7-量化交易专题\n\n\n\n\n\n\n量化交易\n\n\n\nSpecial Topics in Quantitative Trading\n\n\n\n\n\nAug 27, 2021\n\n\n王一刀\n\n\n\n\n\n\n\n\n\n\n\n\nCH5-交易执行系统\n\n\n\n\n\n\n量化交易\n\n\n\nExecutions Systems\n\n\n\n\n\nAug 19, 2021\n\n\n王一刀\n\n\n\n\n\n\n\n\n\n\n\n\nCH4-建立你的事业\n\n\n\n\n\n\n量化交易\n\n\n\nSetting Up Your Business\n\n\n\n\n\nAug 18, 2021\n\n\n王一刀\n\n\n\n\n\n\n\n\n\n\n\n\nCH3-回测\n\n\n\n\n\n\n量化交易\n\n\n\nBacktesting\n\n\n\n\n\nAug 16, 2021\n\n\n王一刀\n\n\n\n\n\n\n\n\n\n\n\n\nCH2-捕获点子\n\n\n\n\n\n\n量化交易\n\n\n\nfishing of ideas\n\n\n\n\n\nAug 13, 2021\n\n\n王一刀\n\n\n\n\n\n\n\n\n\n\n\n\nCH1-量化交易简介\n\n\n\n\n\n\n量化交易\n\n\n\n量化交易是什么，谁参与量化交易，为什么要量化交易\n\n\n\n\n\nAug 12, 2021\n\n\n王一刀\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2021-08-18-setting-up-your-business.html",
    "href": "posts/2021-08-18-setting-up-your-business.html",
    "title": "CH4-建立你的事业",
    "section": "",
    "text": "在中国似乎没有这种选择，很难成为“自营交易公司”的员工。这种公司本身就几乎没有。"
  },
  {
    "objectID": "posts/2021-08-18-setting-up-your-business.html#业务结构零售还是自营",
    "href": "posts/2021-08-18-setting-up-your-business.html#业务结构零售还是自营",
    "title": "CH4-建立你的事业",
    "section": "",
    "text": "在中国似乎没有这种选择，很难成为“自营交易公司”的员工。这种公司本身就几乎没有。"
  },
  {
    "objectID": "posts/2021-08-18-setting-up-your-business.html#选择一家零售经纪公司",
    "href": "posts/2021-08-18-setting-up-your-business.html#选择一家零售经纪公司",
    "title": "CH4-建立你的事业",
    "section": "选择一家零售经纪公司",
    "text": "选择一家零售经纪公司\n主要看佣金，其他的诸如交易速度等等，在现在这个时代已经不是问题了。 * 相对较低的佣金 * 可交易金融工具品种广泛 * 有足够深度的流动资金池 * 获取实时数据和传送指令的API\n这个富途居然有接口https://openapi.futunn.com/futu-api-doc/intro/intro.html\n中泰XTP"
  },
  {
    "objectID": "posts/2021-08-18-setting-up-your-business.html#设备",
    "href": "posts/2021-08-18-setting-up-your-business.html#设备",
    "title": "CH4-建立你的事业",
    "section": "设备",
    "text": "设备\n\n性能良好的电脑\n高速的网络\n防中断电源UPS\n专业实时新闻工具\n多屏幕扩大可视空间"
  },
  {
    "objectID": "posts/2024-08-22-Algorithmic-Trading-2.html",
    "href": "posts/2024-08-22-Algorithmic-Trading-2.html",
    "title": "算法交易：制胜策略与原理(欧内斯特·陈)之二",
    "section": "",
    "text": "我们所说的均值回归并不是指价格的波动，而是指相应收益率通常以均值为零的形式所进行的随机分布。\n在本章中，我所描述的测试和交易策略都是根据时间序列型均值回归模式定制的；有另一种均值回归模式，叫作“横断面”型均值回归，横截面型均值回归意味着一篮子的金融工具之累积收益率将恢复至整个篮子的累积收益水平，这也意味着：短期之内，相应金融工具之相对收益率是连续反相关的（一个金融工具的相对收益率是该项目的收益率减去整个组合篮子的收益率）。\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom statsmodels.tsa.stattools import adfuller\nimport statsmodels.api as sm\n# from genhurst import genhurst \n\ndef genhurst(z):\n# =============================================================================\n# calculation of Hurst exponent given log price series z\n# =============================================================================\n    z=pd.DataFrame(z)\n    # 计算一系列时间延迟 taus，这些时间延迟是时间序列长度的十分之一左右。时间延迟不能与时间序列长度相同，因为这会导致统计不稳定。\n    taus=np.arange(np.round(len(z)/10)).astype(int) # We cannot use tau that is of same magnitude of time series length \n    # 初始化一个空数组 logVar，用于存储每个时间延迟对应的对数方差。\n    logVar=np.empty(len(taus)) # log variance\n    # 对于每个时间延迟 tau，计算 z 的差分序列（即相邻元素之间的差异）的方差，并取对数。将结果存储在 logVar 数组中。\n    for tau in taus:\n        logVar[tau]=np.log(z.diff(tau).var(ddof=0))\n\n    # 创建两个数组 X 和 Y，分别表示时间延迟的对数和对应的对数方差。 \n    X=np.log(taus)    \n    Y=logVar[:len(taus)]\n    # 删除 logVar 中包含非有限值（如NaN或无穷大）的元素对应的 X 和 Y 中的元素。\n    X=X[np.isfinite(logVar)]\n    Y=Y[np.isfinite(logVar)]\n#    pd.DataFrame(np.asmatrix([X, Y]).T).to_csv('XY.csv')\n\n    X = sm.add_constant(X)\n    # plt.scatter(X[:,1], Y) # for debug only\n    # 使用 statsmodels 库中的 OLS 函数拟合一个线性回归模型，其中 Y 是因变量，X 是自变量（包括一个常数项）。\n    model=sm.OLS(Y, X)\n    results=model.fit()\n    # 从拟合结果中提取 Hurst 指数 H（即斜率的一半）和相应的 p 值 pVal\n    H=results.params[1]/2\n    pVal=results.pvalues[1]\n    return H, pVal\n\ndf=pd.read_csv('datas/inputData_USDCAD.csv')\n# print(df)\ndf.set_index('Date',inplace=True)\ny=df.loc[df['Time']==1659, 'Close']\n# 将索引转换为matplotlib可识别的日期格式\ny.index = pd.to_datetime(y.index,format='%Y%m%d')\n# print(y)\nplt.plot(y)\n\n# y：要检验的时间序列。\n# maxlag：最大滞后阶数，用于构建ADF检验的模型。这里设置为1。\n# regression：回归类型。'c'表示在回归模型中包含常数项。\n# autolag：自动选择滞后阶数。这里设置为None，表示不自动选择滞后阶数。\nresults=adfuller(y, maxlag=1, regression='c', autolag=None)\n# adfuller 函数是 statsmodels 库中的一个函数，用于执行 Augmented Dickey-Fuller (ADF) 单位根检验\n# Test Statistic（检验统计量）：这是用于检验单位根假设的统计量。如果此值小于临界值，则拒绝原假设，认为时间序列是平稳的。\n# p-value（p值）：这是检验统计量的概率值。如果 p 值小于预设的显著性水平（通常为 0.05），则拒绝原假设，认为时间序列是平稳的。\n# Critical Values（临界值）：这是一组用于与检验统计量进行比较的值。通常有三个临界值，分别对应于 1%、5% 和 10% 的显著性水平。如果检验统计量小于这些临界值，则拒绝原假设。\n# Number of Lags Used（使用的滞后阶数）：这是用于 ADF 检验的滞后阶数。滞后阶数的选择会影响检验的结果。\n# Number of Observations Used in Regression Analysis（回归分析中使用的观测值数量）：这是用于回归分析的观测值数量。\n# Critical Values (1%, 5%, and 10%)（临界值，1%、5% 和 10%）：这是一组用于与检验统计量进行比较的值，分别对应于 1%、5% 和 10% 的显著性水平。\n# ADF Statistic（ADF 统计量）：这是 ADF 检验的主要统计量，与 Test Statistic 相同。\n# p-value (Adjusted)（调整后的 p 值）：这是调整后的 p 值，考虑了滞后阶数的选择。\nprint(results)\n\n# Find Hurst exponent\nH, pVal=genhurst(np.log(y))\nprint(\"H=%f pValue=%f\" % (H, pVal))\n\n(-1.8430182830405568, 0.35932298598891743, 1, 1214, {'1%': -3.4357480073434905, '5%': -2.863923702481129, '10%': -2.568039121778048})\nH=0.475844 pValue=0.000000\n\n\nC:\\Users\\win10\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n  result = getattr(ufunc, method)(*inputs, **kwargs)\nC:\\Users\\win10\\AppData\\Local\\Temp\\ipykernel_22572\\527508146.py:22: RuntimeWarning: divide by zero encountered in log\n  X=np.log(taus)\n\n\n\n\n\n\n\n\n\n(-1.8430182830405568, 0.35932298598891743, 1, 1214, {‘1%’: -3.4357480073434905, ‘5%’: -2.863923702481129, ‘10%’: -2.568039121778048}) 这个结果来自ADF单位根检验，以下是对结果的解读：\nADF统计量：-1.8430182830405568\np值：0.35932298598891743\n使用的滞后阶数：1\n观测值数量：1214\n临界值：{‘1%’: -3.4357480073434905, ‘5%’: -2.863923702481129, ‘10%’: -2.568039121778048}\n根据ADF单位根检验的结果，我们可以得出以下结论：\nADF统计量为-1.8430182830405568，小于5%的临界值-2.863923702481129，但大于10%的临界值-2.568039121778048。 p值为0.35932298598891743，大于预设的显著性水平0.05。\n由于ADF统计量大于10%的临界值，且p值大于0.05，我们不能拒绝原假设，即时间序列存在单位根，因此时间序列是非平稳的。\n将回归系数λ和均值回归的半衰期连接在一起对交易者来说非常有用，其原因是： * 第一，如果我们发现λ是正值，那么就意味着价格系列并不是均值回归的形态，甚至我们不应该试图以均值回归的策略去进行相关交易； * 第二，如果λ值非常接近于零，这意味着半衰期很长，运用均值回归的交易策略将不会很赚钱，因为我们无法在给在给定的时间范围内完成许多个回合的交易； * 第三，这个λ也可以为我们交易策略中的许多参数决定一个自然的时间尺度。\n\ndf=pd.read_csv('datas/inputData_USDCAD.csv')\n# print(df)\ndf.set_index('Date',inplace=True)\ny=df.loc[df['Time']==1659, 'Close']\n# 将索引转换为matplotlib可识别的日期格式\ny.index = pd.to_datetime(y.index,format='%Y%m%d')\ny = y[y.notna().values] #删除包含缺失值的行。\n# print(y)\n# plt.plot(y)\nylag = y.shift() #创建一个滞后变量\n# print(ylag)\ndeltay = y - ylag #计算收盘价的差分\n# print(deltay)\ndeltay = deltay[1:] #删除第一个NaN值\n# print(deltay)\n\n# print(ylag[1:])\nX=sm.add_constant(ylag[1:]) # 为滞后变量添加常数项\n# print(X)\nmodel=sm.OLS(deltay, X) #创建一个线性回归模型\nres=model.fit() #拟合模型\nhalflife=-np.log(2)/res.params[1] #计算半衰期\nprint('halflife:',halflife)\n\nhalflife: 115.20979448515476\n\n\n如果我们可以找到一个由几个非平稳的价格系列所构建的平稳的线性组合，那么，这些价格系列则被称之为协整形式。\n如果我们能结合两个或多个非平稳的价格系列组成平稳的投资组合，那么这些价格系列被称为协整。\n协整可以用CADF测试或约翰森测试进行测试。\n加强版的ADF检验（CADF）和约翰森检验的模式。前者是只适合一对价格系列，而后者则适用于任何数量的价格系列。\n一个特定资产的对冲比率是在投资组合中我们应该做多，或做空多大数量的单位资产——如果资产是股票，那么单位数量所对应的就是股票的股数，而一个负的对冲比率表明我们应该做空此类资产.\n首先通过运行两个价格系列之间的线性回归的相关性来确定最优的对冲比率，然后使用这种对冲比率形成相应的投资组合，最后在该组合之内对相应的价格系列进行平稳性的测试\nEWA：iShares MSCI Australia ETF，是一种交易所交易基金，旨在追踪澳大利亚股票市场的表现。\nEWC：iShares MSCI Canada ETF，同样是一种交易所交易基金，旨在追踪加拿大股票市场的表现。\nIGE：一个由自然资源类股票所构成的基金。\n\n# Using the CADF test for cointegration\n\nimport numpy as np\nimport pandas as pd\n#import matplotlib.pyplot as plt\nimport statsmodels.formula.api as sm\nimport statsmodels.tsa.stattools as ts\nimport statsmodels.tsa.vector_ar.vecm as vm\n\ndf=pd.read_csv('datas/inputData_EWA_EWC_IGE.csv')\ndf['Date']=pd.to_datetime(df['Date'],  format='%Y%m%d').dt.date # remove HH:MM:SS\ndf.set_index('Date', inplace=True)\n# 绘制EWA和EWC的时间序列图\ndf.plot()\n# 绘制EWA和EWC的散点图\ndf.plot.scatter(x='EWA', y='EWC')\n# 使用普通最小二乘法（OLS）拟合EWA和EWC之间的关系\nresults=sm.ols(formula=\"EWC ~ EWA\", data=df[['EWA', 'EWC']]).fit()\n# 这行代码打印出模型的参数，包括截距和斜率\nprint(results.params)\n# 计算对冲比率\nhedgeRatio=results.params[1]\nprint('hedgeRatio=%f' % hedgeRatio)\n# 绘制残差图\npd.DataFrame((df['EWC']-hedgeRatio*df['EWA'])).plot()\n\n# cadf test\ncoint_t, pvalue, crit_value=ts.coint(df['EWA'], df['EWC'])\n# coint_t：t统计量，用于检验两个序列是否协整。\n# pvalue：p值，用于判断t统计量的显著性。如果p值小于某个显著性水平（如0.05），则拒绝原假设（即两个序列不协整）。\n# crit_value：临界值，用于与t统计量进行比较。\nprint('t-statistic=%f' % coint_t)\nprint('pvalue=%f' % pvalue)\nprint('crit_value:',crit_value)\n\n# Johansen test\nresult=vm.coint_johansen(df[['EWA', 'EWC']].values, det_order=0, k_ar_diff=1)\n# result.lr1：第一个特征值的迹统计量。\n# result.cvt：第一个特征值的临界值。\n# result.lr2：第二个特征值的迹统计量。\n# result.cvm：第二个特征值的临界值。\n# 约翰森检验的输出结果包括迹统计量和相应的临界值，用于判断多个时间序列之间是否存在协整关系。如果迹统计量大于临界值，则拒绝原假设（即不存在协整关系）。\nprint(result)\nprint('result.lr1:',result.lr1)\nprint('result.cvt:',result.cvt)\nprint('result.lr2:',result.lr2)\nprint('result.cvm:',result.cvm)\n\n# Add IGE for Johansen test\nresult=vm.coint_johansen(df.values, det_order=0, k_ar_diff=1)\nprint(result)\nprint('result.lr1:',result.lr1)\nprint('result.cvt:',result.cvt)\nprint('result.lr2:',result.lr2)\nprint('result.cvm:',result.cvm)\n# 特征值\nprint('result.eig:',result.eig) # eigenvalues\n# 特征向量\nprint('result.evec:',result.evec) # eigenvectors\n\n# 计算投资组合的市值   result.evec[:, 0] 是一个NumPy数组操作，它表示从result.evec这个二维数组中取出所有行（用 : 表示）的第0列（用 0 表示）的元素\n# np.dot 是 NumPy 库中的一个函数，用于计算两个数组的点积。它可以用于计算两个向量的点积，或者计算一个矩阵与另一个矩阵的乘积。\n# 这里的\"市值\"并不是传统意义上的市值，而是通过主成分分析得到的一个度量值。这个度量值可以帮助我们理解数据的主要变化趋势和结构。\nyport=pd.DataFrame(np.dot(df.values, result.evec[:, 0])) #  (net) market value of portfolio\nylag=yport.shift()\ndeltaY=yport-ylag\ndf2=pd.concat([ylag, deltaY], axis=1)\ndf2.columns=['ylag', 'deltaY']\nregress_results=sm.ols(formula=\"deltaY ~ ylag\", data=df2).fit() # Note this can deal with NaN in top row\nprint(regress_results.params)\n\nhalflife=-np.log(2)/regress_results.params['ylag']\nprint('halflife=%f days' % halflife)\n\n#  Apply a simple linear mean reversion strategy to EWA-EWC-IGE\n # 设置回望期为上面找到的半衰期\nlookback=np.round(halflife).astype(int) #  setting lookback to the halflife found above\n# yport.rolling(lookback).mean() 计算了一个移动平均值，窗口大小为 lookback。这个移动平均值代表了在过去 lookback 个时间点的平均市值。\n# yport.rolling(lookback).std() 计算了一个移动标准差，窗口大小为 lookback。这个移动标准差代表了在过去 lookback 个时间点的市值波动程度。\n# (yport - yport.rolling(lookback).mean()) 计算了每个时间点的市值与其移动平均值的差值。正值表示市值高于平均值，负值表示市值低于平均值。\n# -(yport - yport.rolling(lookback).mean()) / yport.rolling(lookback).std() 计算了每个时间点的单位数量。正值表示买入，负值表示卖出。单位数量的计算公式为：(市值 - 移动平均值) / 移动标准差。这个公式实际上计算了一个标准化后的差值，使得单位数量在不同的时间点和不同的投资组合之间具有可比性。\nnumUnits =-(yport-yport.rolling(lookback).mean())/yport.rolling(lookback).std() # capital invested in portfolio in dollars.  movingAvg and movingStd are functions from epchan.com/book2\nprint('numUnits:',numUnits)\n# 计算了基于线性均值回归策略的投资组合的市值分布\n# result.evec[:, 0] 是一个一维数组，表示第一个特征向量。这个特征向量是从主成分分析（PCA）或其他类似方法中得到的。\n# np.expand_dims(result.evec[:, 0], axis=1).T 将一维数组转换为二维数组，并进行转置。这样做的目的是为了使其能够与 numUnits.values 相乘。\n# np.dot(numUnits.values, np.expand_dims(result.evec[:, 0], axis=1).T) 计算单位数量与特征向量的点积。这个点积表示每个投资组合单位在第一个特征向量方向上的投影。\n# np.dot(numUnits.values, np.expand_dims(result.evec[:, 0], axis=1).T) * df.values 将点积结果与原始数据相乘，得到每个投资组合单位在每个资产上的市值。\npositions=pd.DataFrame(np.dot(numUnits.values, np.expand_dims(result.evec[:, 0], axis=1).T)*df.values) # results.evec(:, 1)' can be viewed as the capital allocation, while positions is the dollar capital in each ETF.\nprint('positions:',positions)\nprint('np.expand_dims(result.evec[:, 0], axis=1).T : ',np.expand_dims(result.evec[:, 0], axis=1).T)\nprint('np.dot(numUnits.values, np.expand_dims(result.evec[:, 0], axis=1).T):',np.dot(numUnits.values, np.expand_dims(result.evec[:, 0], axis=1).T))\n# 计算了基于线性均值回归策略的投资组合的每日收益（P&L）\n# positions.shift().values：将 positions DataFrame 向前移动一个时间点，得到前一天的投资组合市值。\n# df.pct_change().values：计算原始数据（df）的每日百分比变化。\n# (positions.shift().values)*(df.pct_change().values)：将前一天的投资组合市值与每日百分比变化相乘，得到每日收益。\n# np.sum((positions.shift().values)*(df.pct_change().values), axis=1)：沿着列方向（axis=1）求和，得到每个时间点的总收益。\npnl=np.sum((positions.shift().values)*(df.pct_change().values), axis=1) # daily P&L of the strategy\n# pnl：上一行代码计算出的每日收益。\n# np.sum(np.abs(positions.shift()), axis=1)：计算前一天的投资组合市值的绝对值之和。\n# ret = pnl / np.sum(np.abs(positions.shift()), axis=1)：将每日收益除以前一天的投资组合市值的绝对值之和，得到每日收益率。\nret=pnl/np.sum(np.abs(positions.shift()), axis=1)\n# np.cumprod(1+ret)：计算每日收益率的累积乘积，得到累计收益率。\n# np.cumprod(1+ret)-1：将累计收益率减去1，得到累计收益。\npd.DataFrame((np.cumprod(1+ret)-1)).plot()\nprint('============')\nprint('np.prod(1+ret):',np.prod(1+ret))\nprint('252/len(ret):',252/len(ret))\n# np.prod() 是 NumPy 库中的一个函数，用于计算数组中所有元素的乘积。这个函数可以用于计算一组数值的乘积，例如计算一组收益率的乘积以得到累积收益率。\nprint('APR=%f Sharpe=%f' % (np.prod(1+ret)**(252/len(ret))-1, np.sqrt(252)*np.mean(ret)/np.std(ret)))\n# APR=0.125739 Sharpe=1.391310\n\nIntercept    6.411331\nEWA          0.962429\ndtype: float64\nhedgeRatio=0.962429\nt-statistic=-3.063528\npvalue=0.095866\ncrit_value: [-3.90376106 -3.34020915 -3.04728056]\n&lt;statsmodels.tsa.vector_ar.vecm.JohansenTestResult object at 0x000001E479B796D0&gt;\nresult.lr1: [19.98321869  3.98276124]\nresult.cvt: [[13.4294 15.4943 19.9349]\n [ 2.7055  3.8415  6.6349]]\nresult.lr2: [16.00045745  3.98276124]\nresult.cvm: [[12.2971 14.2639 18.52  ]\n [ 2.7055  3.8415  6.6349]]\n&lt;statsmodels.tsa.vector_ar.vecm.JohansenTestResult object at 0x000001E40D6A4490&gt;\nresult.lr1: [34.42862022 17.53171895  4.47102054]\nresult.cvt: [[27.0669 29.7961 35.4628]\n [13.4294 15.4943 19.9349]\n [ 2.7055  3.8415  6.6349]]\nresult.lr2: [16.89690127 13.06069841  4.47102054]\nresult.cvm: [[18.8928 21.1314 25.865 ]\n [12.2971 14.2639 18.52  ]\n [ 2.7055  3.8415  6.6349]]\nresult.eig: [0.01121626 0.00868086 0.00298021]\nresult.evec: [[ 0.7599635  -0.11204898  0.0789828 ]\n [-1.04602749 -0.5796762   0.26467204]\n [ 0.22330592  0.53159644 -0.09515547]]\nIntercept   -0.115768\nylag        -0.030586\ndtype: float64\nhalflife=22.662578 days\nnumUnits:              0\n0          NaN\n1          NaN\n2          NaN\n3          NaN\n4          NaN\n...        ...\n1495  1.266708\n1496  0.694832\n1497 -0.277333\n1498 -1.594578\n1499 -1.588591\n\n[1500 rows x 1 columns]\npositions:               0          1          2\n0           NaN        NaN        NaN\n1           NaN        NaN        NaN\n2           NaN        NaN        NaN\n3           NaN        NaN        NaN\n4           NaN        NaN        NaN\n...         ...        ...        ...\n1495  22.747467 -38.160335  11.280594\n1496  12.282373 -20.619697   6.125721\n1497  -4.843326   8.085019  -2.399788\n1498 -28.017310  46.219527 -13.694791\n1499 -27.682721  45.630541 -13.480184\n\n[1500 rows x 3 columns]\nnp.expand_dims(result.evec[:, 0], axis=1).T :  [[ 0.7599635  -1.04602749  0.22330592]]\nnp.dot(numUnits.values, np.expand_dims(result.evec[:, 0], axis=1).T): [[        nan         nan         nan]\n [        nan         nan         nan]\n [        nan         nan         nan]\n ...\n [-0.21076268  0.29009756 -0.06193002]\n [-1.21182137  1.66797282 -0.3560788 ]\n [-1.20727087  1.66170944 -0.35474169]]\n============\nnp.prod(1+ret): 2.0238397644099786\n252/len(ret): 0.168\nAPR=0.125739 Sharpe=1.402653\n\n\nC:\\Users\\win10\\AppData\\Local\\Temp\\ipykernel_15472\\4197053767.py:22: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  hedgeRatio=results.params[1]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n在约翰森检测结果中，我们应该期待第一协整关系是“最强”的，也就是说，相应均值回归的半衰期最短，进而使我们很自然地选择这个特征向量形成平稳的投资组合（特征向量可以确定ETF基金内各类资产的权重），同时，我们可以用与之前相同的方法发现其半衰期，并应对一个平稳的价格系列。\n均值回归之配对交易的背后通常都有一个基本的原理：为什么EWA基金要和EWC基金之间进行协整呢？这是因为加拿大和澳大利亚的经济中，占主导地位的是大宗商品交易。那么，股票指数型基金GDX为什么要和黄金GLD协整呢？这是因为金矿公司的市值是基于黄金价值的。即使一对协整关系破裂（停止协整），我们通常都要对其分崩离析的原因进行解析。例如，在第4章的分析中，我们发现GDX基金和黄金GLD的协整关系在2008年年初便处于解体的状态，而能源价格的高腾导致黄金的开采异常昂贵。\n交易策略相关的另一个极端情境是：依赖于基本面分析的投资者偏好于投资那些被低估并持有很多年的股票，耐心地等待它们的价格回归至“正常”的价值水平。\n短时间内完成交易对我们这一类交易者最有利，因为较短的时间尺度意味着每年有更高的交易数量，进而使我们的回测系统与实时交易具有更高的统计信心和更高的夏普比率，最终使我们的交易策略具有更高的复合收益率。\n看似具有很高一致性的均值回归的交易策略最终可能会失效。迈克尔·德弗指出，这种高度一致性经常会使相关的交易员过度自信，且过度举债（德弗，2011）（考虑一下长期的资本管理问题）。当均值回归交易策略突然崩坏，其原因也许是我们都是“事后诸葛亮”，而且，此类事件经常发生在我们以此策略获得一系列成功之后、加大交易杠杆之时，由此而产生的罕见的损失往往是非常痛苦的，有时是灾难性的。因此，所谓的风险管理的概念对均值回归型的交易者尤为重要，但也特别困难，因为通常意义上的止损是不能按逻辑进行部署的。\n\nimport datetime\nimport numpy as np\nimport pandas as pd\nimport backtrader as bt\nimport statsmodels.tsa.vector_ar.vecm as vm\nimport statsmodels.formula.api as sm\nimport statsmodels.tsa.stattools as ts\n# 读取CSV文件\ndata_df = pd.read_csv('datas/inputData_EWA_EWC_IGE.csv')\n\n# 将日期列转换为datetime类型\ndata_df['Date'] = pd.to_datetime(data_df['Date'], format='%Y%m%d')\ndata_df.set_index('Date', inplace=True)\n\nresult=vm.coint_johansen(data_df.values, det_order=0, k_ar_diff=1)\nprint(\"特征值：\", result.eig)\nprint(\"特征向量：\", result.evec)\nprint(\"迹统计量：\", result.lr1)\nprint(\"迹统计量的临界值：\", result.cvt)\nprint(\"最大特征值统计量：\", result.lr2)\nprint(\"最大特征值统计量的临界值：\", result.cvm)\n\nprint(result.cvt[:, 0])\nprint('result.lr1 &gt; result.cvt[:, 0]:',result.lr1 &gt; result.cvt[:, 0])\nprint('np.any(result.lr1 &gt; result.cvt[:, 0]):',np.any(result.lr1 &gt; result.cvt[:, 0]))\n\n# 二维三列矩阵和特征向量相乘  即每种产品价格和占比相乘后相加 得到总市值\nprint('result.evec[:, 0]:',result.evec[:, 0])\nyport=pd.DataFrame(np.dot(data_df.values, result.evec[:, 0]),columns=['close']) \n# print(yport) 算出的值都是负值，整体上是空头，基本没法玩\nylag=yport.shift()\ndeltaY=yport-ylag\ndf2=pd.concat([ylag, deltaY], axis=1)\ndf2.columns=['ylag', 'deltaY']\nregress_results=sm.ols(formula=\"deltaY ~ ylag\", data=df2).fit() # Note this can deal with NaN in top row\nprint(regress_results.params)\n\nhalflife=-np.log(2)/regress_results.params['ylag']\nprint('halflife=%f days' % halflife)\nlookback=np.round(halflife).astype(int)\nnumUnits =-(yport-yport.rolling(lookback).mean())/yport.rolling(lookback).std() \n# print(numUnits)\n# 为yport增加索引列\nyport.index = data_df.index\n\nyport.plot()\n# print(yport.iloc[0])\n# data_df = data_df.reset_index()\ndata_EWA_new = data_df[['EWA']].rename(columns={'EWA':'close'})\ndata_EWC_new = data_df[['EWC']].rename(columns={'EWC':'close'})\ndata_IGE_new = data_df[['IGE']].rename(columns={'IGE':'close'})\n\n# print('data_EWA_new:',data_EWA_new)\n# 创建PandasData对象\ndata_EWA = bt.feeds.PandasData(dataname=data_EWA_new)\ndata_EWC = bt.feeds.PandasData(dataname=data_EWC_new)\ndata_IGE = bt.feeds.PandasData(dataname=data_IGE_new)\n\n\nclass TestStrategy(bt.Strategy):\n    def __init__(self, lookback, proportion ):\n        self.lookback = lookback\n        self.proportion  = proportion \n        self.ctg_price = self.datas[0].close\n        self.EWA = self.datas[1].close\n        self.EWC = self.datas[2].close\n        self.IGE = self.datas[3].close\n        print('__init__', lookback, proportion)\n        print('__init__',self.datas[0].buflen())\n        print('__init__',self.datas[1].buflen())\n        print('__init__',self.datas[2].buflen())\n        print('__init__',self.datas[3].buflen())\n        # print('__init__',self.datas[0].close[0])\n        print(type(self.proportion))\n        # 创建一个滚动窗口均值指标  Add a MovingAverageSimple indicator\n        self.mean = bt.indicators.SimpleMovingAverage(self.datas[0], period=self.lookback)\n        # 创建一个滚动窗口标准差指标  \n        self.std = bt.indicators.StandardDeviation(self.datas[0], period=self.lookback)\n        # 使用上面的指标计算标准化差异\n        # self.zscore = -(self.datas[0] - self.mean) / self.std\n        # self.zscore = bt.indicators.ZScore(self.datas[0].close, period=self.params.lookback)\n        print(\"Mean:\", self.mean.buflen())  # 注意：索引 0 可能在第一个数据点上不可用  此时均值并没有计算，只有在next中才会实时计算\n        print(\"Std Dev:\", self.std.buflen())  \n        # print(\"Z-Score:\", self.zscore.buflen())  \n\n    def next(self):\n        # 在这里编写你的策略逻辑\n        # 你可以使用 self.param1 和 self.param2 访问传递的参数\n        # print(self.data.datetime.date(0))\n        # print(self.datas[0].close[0])\n        # print('price:',self.data.close[0])\n        # print('price:',self.ctg_price[0])\n        # print('EWA price:',self.EWA[0])\n        # print('EWC price:',self.EWC[0])\n        # print('IGE price:',self.IGE[0])\n        # print(self.ctg_price[0])\n         # 检查是否有足够的数据点来计算均值和标准差  \n        if len(self.mean) &gt; 0 and len(self.std) &gt; 0:  \n            # 计算当前的 Z-score  \n            # 注意：我们需要确保标准差不为0（虽然在实际金融数据中这很少见）  \n            if self.std[0] != 0:  \n                z = -(self.ctg_price[0] - self.mean[0]) / self.std[0]  # 这个买入还是卖出问题还没闹清楚\n                self.zscore = z  # 存储 Z-score 值以便后续使用（如果需要的话）\n                # print('zscore:',self.zscore)\n                positions = self.zscore*self.proportion\n                # print('positions:',positions)\n                # 这里计算权重的方法并不确定\n                w1 = (positions[0]/np.abs(positions).sum()).round(2)\n                w2 = (positions[1]/np.abs(positions).sum()).round(2)\n                w3 = (positions[2]/np.abs(positions).sum()).round(2)\n                # print('w1:',w1)\n                # print('w2:',w2)\n                # print('w3:',w3)\n                if self.zscore &gt; 0:  # 买入\n                    # print(\"卖出！ Current Z-Score:\", z)\n                    # print('比例：',self.proportion)\n                    # self.sell(data=self.datas[0],size=1000)\n                    if w1 &gt; 0:\n                        self.buy(data=self.datas[1],size=1000*w1)\n                    else:\n                        self.sell(data=self.datas[1],size=1000*np.abs(w1))\n                    if w2 &gt; 0:\n                        self.buy(data=self.datas[2],size=1000*w2)\n                    else:\n                        self.sell(data=self.datas[2],size=1000*np.abs(w2))\n                    if w3 &gt; 0:\n                        self.buy(data=self.datas[3],size=1000*w3)\n                    else:\n                        self.sell(data=self.datas[3],size=1000*np.abs(w3))\n                    # print(self.sell())\n                elif self.zscore &lt; 0: # 卖出\n                    # print(\"买入！ Current Z-Score:\", z)\n                    # print('比例：',self.proportion)\n                    # self.buy(data=self.datas[0],size=1000)\n                    # print(self.buy())\n                    if w1 &gt; 0:\n                        self.sell(data=self.datas[1],size=1000*w1)\n                    else:\n                        self.buy(data=self.datas[1],size=1000*np.abs(w1))\n                    if w2 &gt; 0:\n                        self.sell(data=self.datas[2],size=1000*w2)\n                    else:\n                        self.buy(data=self.datas[2],size=1000*np.abs(w2))\n                    if w3 &gt; 0:\n                        self.sell(data=self.datas[3],size=1000*w3)\n                    else:\n                        self.buy(data=self.datas[3],size=1000*np.abs(w3))\n            else:  \n                print(\"Standard deviation is zero, cannot calculate Z-Score.\")\n\n# 创建 cerebro 实例\ncerebro = bt.Cerebro()\n# 初始资金 100,000,000\ncerebro.broker.setcash(100000000.0)\n# 佣金，双边各 0.0003\ncerebro.broker.setcommission(commission=0.0003)\n# 滑点：双边各 0.0001\ncerebro.broker.set_slippage_perc(perc=0.0001)\n# 这里有点问题，并没有得出分析结果\ncerebro.addanalyzer(bt.analyzers.TimeReturn, _name='pnl') # 返回收益率时序数据\ncerebro.addanalyzer(bt.analyzers.AnnualReturn, _name='_AnnualReturn') # 年化收益率\ncerebro.addanalyzer(bt.analyzers.SharpeRatio, _name='_SharpeRatio') # 夏普比率\ncerebro.addanalyzer(bt.analyzers.DrawDown, _name='_DrawDown') # 回撤\n\ncerebro.addstrategy(TestStrategy, lookback=lookback, proportion=result.evec[:, 0])\n# 保存6位小数，解决策略中小数点位数边长的问题\nyport['close'] = yport['close'].round(6)\n# data_price =  bt.feeds.PandasData(dataname=yport, fromdate=datetime.datetime(2006, 4, 26), todate=datetime.datetime(2006, 4, 30))\ndata_price =  bt.feeds.PandasData(dataname=yport)\ncerebro.adddata(data_price)\ncerebro.adddata(data_EWA)\ncerebro.adddata(data_EWC)\ncerebro.adddata(data_IGE)\nprint(\"组合初始值:\",cerebro.broker.getvalue())\nresult = cerebro.run()\nprint(\"组合终结值:\",cerebro.broker.getvalue())\nprint('result:',result[0])\nstrat = result[0]\n# 返回日度收益率序列\ndaily_return = pd.Series(strat.analyzers.pnl.get_analysis())\n# 打印评价指标\nprint(\"--------------- AnnualReturn -----------------\")\nprint(strat.analyzers._AnnualReturn.get_analysis())\nprint(\"--------------- SharpeRatio -----------------\")\nprint(strat.analyzers._SharpeRatio.get_analysis())\nprint(\"--------------- DrawDown -----------------\")\nprint(strat.analyzers._DrawDown.get_analysis())\n\n特征值： [0.01121626 0.00868086 0.00298021]\n特征向量： [[ 0.7599635  -0.11204898  0.0789828 ]\n [-1.04602749 -0.5796762   0.26467204]\n [ 0.22330592  0.53159644 -0.09515547]]\n迹统计量： [34.42862022 17.53171895  4.47102054]\n迹统计量的临界值： [[27.0669 29.7961 35.4628]\n [13.4294 15.4943 19.9349]\n [ 2.7055  3.8415  6.6349]]\n最大特征值统计量： [16.89690127 13.06069841  4.47102054]\n最大特征值统计量的临界值： [[18.8928 21.1314 25.865 ]\n [12.2971 14.2639 18.52  ]\n [ 2.7055  3.8415  6.6349]]\n[27.0669 13.4294  2.7055]\nresult.lr1 &gt; result.cvt[:, 0]: [ True  True  True]\nnp.any(result.lr1 &gt; result.cvt[:, 0]): True\nresult.evec[:, 0]: [ 0.7599635  -1.04602749  0.22330592]\nIntercept   -0.115768\nylag        -0.030586\ndtype: float64\nhalflife=22.662578 days\n组合初始值: 100000000.0\n__init__ 23 [ 0.7599635  -1.04602749  0.22330592]\n__init__ 1500\n__init__ 1500\n__init__ 1500\n__init__ 1500\n&lt;class 'numpy.ndarray'&gt;\nMean: 0\nStd Dev: 0\n组合终结值: nan\nresult: &lt;__main__.TestStrategy object at 0x000001E40E83B5B0&gt;\n--------------- AnnualReturn -----------------\nOrderedDict([(2006, nan), (2007, nan), (2008, nan), (2009, nan), (2010, nan), (2011, nan), (2012, nan)])\n--------------- SharpeRatio -----------------\nOrderedDict([('sharperatio', nan)])\n--------------- DrawDown -----------------\nAutoOrderedDict([('len', 1477), ('drawdown', nan), ('moneydown', nan), ('max', AutoOrderedDict([('len', 1477), ('drawdown', 0.0), ('moneydown', 0.0)]))])"
  },
  {
    "objectID": "posts/2021-08-27-money-and-risk-management.html",
    "href": "posts/2021-08-27-money-and-risk-management.html",
    "title": "CH6-资金和风险管理",
    "section": "",
    "text": "想从量化交易中赚钱，风险管理至关重要，把挫跌控制在可接受的范围内，把头寸建在净值的最优杠杆水平上，才能实现财富的最大可能增长。 我们要用的主要工具是凯利公式。"
  },
  {
    "objectID": "posts/2021-08-27-money-and-risk-management.html#最佳资本配置和杠杆",
    "href": "posts/2021-08-27-money-and-risk-management.html#最佳资本配置和杠杆",
    "title": "CH6-资金和风险管理",
    "section": "最佳资本配置和杠杆",
    "text": "最佳资本配置和杠杆\n假设计划进行几个策略的交易，每个策略都有其预期收益和标准差。那么，如何在这些策略之间进行最优的资本配置呢？\n我们的优化目标是长期财富最大化。一定要避免赔光。\n假设策略i(这里用i代表第i个策略)的收益率服从正态分布，其均值\\(m_i\\)和标准差\\(s_i\\)已给定。\n用列向量\n\\(F^* = (f_1^* ,f_2^* ,...,f_n^* )^T\\)\n表示分配到n个策略的最优净值比例，其中T代表转置。\n给定优化目标并假设收益率服从正态分布，Thorp不是给出了以下最优配置公式：\n\\(F^* = C^{-1}M\\)\n\nC表示协方差矩阵，矩阵的元素\\(C_ij\\)表示第i 个策略和第j个策略收益率的协方差，-1表示矩阵的逆\n\\(M = (m_1,m_2,...,m_n)^T\\) 表示策略平均收益率的列向量\n\n如果假设所有策略在统计上独立，协方差矩阵就变为对角矩阵，对角线元素等于每个策略收益率的方差，公式：\n\\(f_i = m_i/s_i^2\\)\n这就是著名的凯利公式。"
  },
  {
    "objectID": "posts/2021-08-27-money-and-risk-management.html#做好心理准备",
    "href": "posts/2021-08-27-money-and-risk-management.html#做好心理准备",
    "title": "CH6-资金和风险管理",
    "section": "做好心理准备",
    "text": "做好心理准备\n\n禀赋效应、安于现状偏差、亏损厌恶\n代表性偏差（即人们倾向于对近期经验赋予过多权重，而低估了长期平均的作用）\n恐惧和贪婪"
  },
  {
    "objectID": "posts/2021-08-27-money-and-risk-management.html#收益率正态分布时凯利公式的简单推导",
    "href": "posts/2021-08-27-money-and-risk-management.html#收益率正态分布时凯利公式的简单推导",
    "title": "CH6-资金和风险管理",
    "section": "收益率正态分布时凯利公式的简单推导",
    "text": "收益率正态分布时凯利公式的简单推导\n适用于正态分布的复合杠杆增长率公式为：\n\\(g(f) = r + fm - s^2f^2/2\\)\n\nf为杠杆\nr为无风险利率\nm为平均非复合单期超额收益率\ns为非复合单期收益率的标准差\n\n为了得出使g最大化时的f，令g对f的一阶导数为零：\n\\(dg/df = m - s^2f = 0\\)\n由等式可得\\(f=m/s^2\\), 即为正态分布下策略或政权的凯利公式。"
  },
  {
    "objectID": "posts/2021-08-12-the-whats-whos-and-whys-of-quantitative-trading.html",
    "href": "posts/2021-08-12-the-whats-whos-and-whys-of-quantitative-trading.html",
    "title": "CH1-量化交易简介",
    "section": "",
    "text": "Quantitative trading, also known as algorithmic trading, is the trading of securities based strictly on the buy/sell decisions of computer algorithms. The computer algorithms are designed and perhaps programmed by the traders themselves, based on the historical performance of the encoded strategy tested against historical financial data.\n\n定量交易，也被称为算法交易，是一种严格基于计算机算法买卖决策的证券交易。计算机算法是由交易员自己设计甚至编写的，并根据历史财务数据测试编码策略，以确定期历史业绩。\n\nAs long as you can convert information into bits and bytes that the computer can understand, it can be re\u0002garded as part of quantitative trading.\n\n只要您能将信息转换为计算机能够理解的比特和字节，它就可以被视为定量交易的一部分。"
  },
  {
    "objectID": "posts/2021-08-12-the-whats-whos-and-whys-of-quantitative-trading.html#什么是量化交易",
    "href": "posts/2021-08-12-the-whats-whos-and-whys-of-quantitative-trading.html#什么是量化交易",
    "title": "CH1-量化交易简介",
    "section": "",
    "text": "Quantitative trading, also known as algorithmic trading, is the trading of securities based strictly on the buy/sell decisions of computer algorithms. The computer algorithms are designed and perhaps programmed by the traders themselves, based on the historical performance of the encoded strategy tested against historical financial data.\n\n定量交易，也被称为算法交易，是一种严格基于计算机算法买卖决策的证券交易。计算机算法是由交易员自己设计甚至编写的，并根据历史财务数据测试编码策略，以确定期历史业绩。\n\nAs long as you can convert information into bits and bytes that the computer can understand, it can be re\u0002garded as part of quantitative trading.\n\n只要您能将信息转换为计算机能够理解的比特和字节，它就可以被视为定量交易的一部分。"
  },
  {
    "objectID": "posts/2021-08-12-the-whats-whos-and-whys-of-quantitative-trading.html#谁可以成为量化交易员",
    "href": "posts/2021-08-12-the-whats-whos-and-whys-of-quantitative-trading.html#谁可以成为量化交易员",
    "title": "CH1-量化交易简介",
    "section": "谁可以成为量化交易员",
    "text": "谁可以成为量化交易员\n\nThe ideal independent quantitative trader is therefore someone who has some prior experience with finance or computer program\u0002ming, who has enough savings to withstand the inevitable losses and periods without income, and whose emotion has found the right bal\u0002ance between fear and greed.\n\n因此，理想的独立定量交易员是那些有金融或计算机编程经验，有足够的储蓄来承受不可避免的损失和一定时期的无收入，他的情感已经在恐惧和贪婪之间找到了正确的平衡。"
  },
  {
    "objectID": "posts/2021-08-12-the-whats-whos-and-whys-of-quantitative-trading.html#量化交易的特点",
    "href": "posts/2021-08-12-the-whats-whos-and-whys-of-quantitative-trading.html#量化交易的特点",
    "title": "CH1-量化交易简介",
    "section": "量化交易的特点",
    "text": "量化交易的特点\n\n易扩大\n\nIt is easy to find yourselves trading millions of dollars in the comfort of your own home, as long as your strategy is consistently profitable. This is because scaling up often just means changing a number in your program.\n\n如果你的策略可以持续产生收益的话，扩大规模仅仅意味着在你的程序里修改一个数字。\n\n\n时间自由\n\nif you treasure your leisure time or if you need time and financial resources to explore other businesses, quantitative trading is the business for you.\n\n如果你珍惜你的闲暇时间，或者如果你需要时间和财力来探索其他业务，那么量化交易正适合你。\n\n\n无需市场营销\n\nIn trading, your counterparties in the financial marketplace base their purchase decisions on nothing but the price. Unless you are managing money for other people (which is beyond the scope of this book), there is absolutely no marketing to do in a quantitative trading business.\n\n在交易中，你在金融市场上的交易对手，他们的购买决定只基于价格。除非你是在为其他人管理资金(这超出了本书的范围),在量化交易业务中，绝对没有营销要做。\n\nthe business of quantitative trading allows you to focus exclusively on your product (the strategy and the software), and not on anything that has to do with influencing other people’s perception of yourself.\n\n量化交易业务允许你只专注于你的产品（策略和软件），而不需要做任何影响他人对你自己看法的事。"
  },
  {
    "objectID": "posts/2021-08-12-the-whats-whos-and-whys-of-quantitative-trading.html#前方的路",
    "href": "posts/2021-08-12-the-whats-whos-and-whys-of-quantitative-trading.html#前方的路",
    "title": "CH1-量化交易简介",
    "section": "前方的路",
    "text": "前方的路\n\nIf you are convinced that you want to become a quantitative trader,a number of questions immediately follow: How do you find the right strategy to trade? How do you recognize a good versus a bad strategy even before devoting any time to backtesting them? How do you rigorously backtest them? If the backtest performance is good, what steps do you need to take to implement the strategy, in terms of both the business structure and the technological infrastructure? If the strategy is profitable in initial real-life trading, how does one scale up the capital to make it into a growing income stream while managing the inevitable (but, hopefully, only occasional) losses that come with trading?\n\n如果你确信要成为一名量化交易员，你需要面对以下问题 * 怎样找到正确的交易策略？ * 在投入时间回测之前怎样区分好坏策略？ * 你怎样严谨地回测你的策略？ * 如果回测效果很好，你要通过哪些步骤实现这些策略，有哪些业务架构和技术基础设施的模式？ * 如果策略在真实交易中获利，怎样在扩大资金规模提升收入流的同时管控交易中不可必免的损失？"
  },
  {
    "objectID": "posts/2021-08-16-backtesting.html",
    "href": "posts/2021-08-16-backtesting.html",
    "title": "CH3-回测",
    "section": "",
    "text": "A key difference between a traditional investment management process and a quantitative investment process is the possibility of back\u0002testing a quantitative investment strategy to see how it would have performed in the past\n量化投资流程和传统投资管理流程最重要的区别是：量化投资策略可以进行回测以观察它在过去的表现。"
  },
  {
    "objectID": "posts/2021-08-16-backtesting.html#常用的回测工具",
    "href": "posts/2021-08-16-backtesting.html#常用的回测工具",
    "title": "CH3-回测",
    "section": "常用的回测工具",
    "text": "常用的回测工具\n\nExcel &gt; The major disadvantage of Excel is that it can be used to backtest only fairly simple models.But, as I explained in the previous chapter, simple models are often the best!\n\nExcel的主要缺点是只能用于简单模型的回测。但是，简单模型往往是最好的。\n\nMATLAB\n\nMATLAB优点很多，功能强大，但是价格昂贵。有一些替代品:\nO-Matrix\nOctave\nScilab\n\nTradeStation\nHigh-End Backtesting Platforms"
  },
  {
    "objectID": "posts/2021-08-16-backtesting.html#寻找并使用历史数据库",
    "href": "posts/2021-08-16-backtesting.html#寻找并使用历史数据库",
    "title": "CH3-回测",
    "section": "寻找并使用历史数据库",
    "text": "寻找并使用历史数据库\n\nWhile finding sources of data on the Internet is even easier than finding prospective strategies, there are a number of issues and pitfalls with many of these databases that I will discuss later in this section. These issues apply mostly to stock and exchange-traded fund (ETF) data only. Here are the most important ones.\n\n虽然在互联网上寻找数据源比寻找有效的策略容易，但这些数据中存在问题和陷阱。下面是最主要的问题，这些问题仅适用股票和交易基金数据。\n\n数据是否已经过分拆和股息调整？\n是否剔除了幸存偏差数据？\n你的策略用最高最低价吗？\n\n\n使用最高最低价的回测没有使用开盘收盘价的回测可靠。\n\n\n业绩度量\n\n夏普比率\n\n年化夏普比率的计算：一般而言，假设每个交易时段的长度为T，T可以是1个月、1天、1小时等，若要计算平均收益率、标准差以及相应的年化指标，就必须先算出一年的交易时段数\\(N_T\\)\n\\(年化夏普比率= \\sqrt {N_T} * 基于T的夏普比率\\)\n年化标准差和日标准差的关系推理：\n\n其中cov是指协方差。\n最大挫跌和最长挫跌期\n\n这个指标算起来挺麻烦，从图中看的话，倒是挺直观。"
  },
  {
    "objectID": "posts/2021-08-16-backtesting.html#避免常见的回测陷阱",
    "href": "posts/2021-08-16-backtesting.html#避免常见的回测陷阱",
    "title": "CH3-回测",
    "section": "避免常见的回测陷阱",
    "text": "避免常见的回测陷阱\n\n前视偏差\n\n例如，“在日最低价的1%之内买入股票”的交易规则，就有前视偏差，因为在当日市场收盘前，是不可能知道日最低价的。\n\n数据迁就偏差\n\n因迁就历史数据的噪声而过度优化模型参数，造成策略的回测业绩高于未来业绩，即为数据迁就偏差。"
  },
  {
    "objectID": "posts/2021-08-16-backtesting.html#交易成本",
    "href": "posts/2021-08-16-backtesting.html#交易成本",
    "title": "CH3-回测",
    "section": "交易成本",
    "text": "交易成本\n没有考虑交易成本的回测业绩是不真实的。"
  },
  {
    "objectID": "posts/2021-08-16-backtesting.html#策略改进",
    "href": "posts/2021-08-16-backtesting.html#策略改进",
    "title": "CH3-回测",
    "section": "策略改进",
    "text": "策略改进\n对基本策略进行微小调整，来提升收益。策略的改进，最好基于经济学基本原理，或者透彻研究过的市场现象，而不是依据一些主观的试错法则。否则，就有可能产生数据迁就偏差。\n\nimport pandas as pd \nimport numpy as np\n\nxlsx = pd.ExcelFile(\"datas/example3_4.xls\")\ndf = pd.read_excel(xlsx,\"table\")\n# 计算每日收益率：\ndf['daily_ret'] = df['Adj Close'].pct_change()\n#假设年化收益率为4%，每年252个交易日 计算每日超额收益\ndf['excess_daily_ret'] = df['daily_ret'] - 0.04/252\n\nsharp_ratio = np.sqrt(252) * df['excess_daily_ret'].mean() / df['excess_daily_ret'].std()\n\nprint(sharp_ratio)\n\n0.7889300350874483"
  },
  {
    "objectID": "posts/2021-12-06-backtrader.html",
    "href": "posts/2021-12-06-backtrader.html",
    "title": "backtrader回测系统",
    "section": "",
    "text": "import datetime\nimport backtrader as bt\nimport pandas as pd\n\nclass TestStrategy(bt.Strategy):\n    params = (\n        ('maperiod', 15),\n    )\n\n    def log(self, txt, dt=None):\n        dt = dt or self.datas[0].datetime.date(0)\n        print('%s, %s' % (dt.isoformat(), txt))\n    def __init__(self):\n        self.dataclose = self.datas[0].close\n        print('buflen %d' % self.dataclose.buflen())\n        self.order = None\n        self.buyprice = None\n        self.buycomm = None\n\n        # Add a MovingAverageSimple indicator\n        self.sma = bt.indicators.SimpleMovingAverage(\n            self.datas[0], period=self.params.maperiod)\n        \n        # Indicators for the plotting show\n        bt.indicators.ExponentialMovingAverage(self.datas[0], period=25)\n        bt.indicators.WeightedMovingAverage(self.datas[0], period=25,\n                                            subplot=True)\n        bt.indicators.StochasticSlow(self.datas[0])\n        bt.indicators.MACDHisto(self.datas[0])\n        rsi = bt.indicators.RSI(self.datas[0])\n        bt.indicators.SmoothedMovingAverage(rsi, period=10)\n        bt.indicators.ATR(self.datas[0], plot=False)\n\n    def notify_order(self, order):\n        if order.status in [order.Submitted, order.Accepted]:\n            return\n        if order.status in [order.Completed]:\n            if order.isbuy():\n                self.log('BUY EXECUTED, Price: %.2f, Cost: %.2f, Comm %.2f' %\n                        (order.executed.price,\n                        order.executed.value,\n                        order.executed.comm))\n                self.buyprice = order.executed.price\n                self.buycomm = order.executed.comm\n            elif order.issell():\n                self.log('SELL EXECUTED, Price: %.2f, Cost: %.2f, Comm %.2f' %\n                         (order.executed.price,\n                          order.executed.value,\n                          order.executed.comm))\n            self.bar_executed = len(self)\n        elif order.status in [order.Canceled, order.Margin, order.Rejected]:\n            self.log('Order Canceled/Margin/Rejected')\n        self.order = None\n\n    def notify_trade(self, trade):\n        if not trade.isclosed:\n            return\n\n        self.log('OPERATION PROFIT, GROSS %.2f, NET %.2f' %\n                 (trade.pnl, trade.pnlcomm))\n\n    def next(self):\n        self.log('Close, %.2f' % self.dataclose[0])\n        if self.order:\n            return\n        if not self.position:\n            if self.dataclose[0] &gt; self.sma[0]:\n                self.log('BUY CREATE, %.2f' % self.dataclose[0])\n                print(self.buy())\n        else:\n            if self.dataclose[0] &lt; self.sma[0]:\n                self.log('SELL CREATE, %.2f' % self.dataclose[0])\n                self.order = self.sell()\n\n\ncerebro = bt.Cerebro()\n\ncerebro.addstrategy(TestStrategy)\n\ndata = bt.feeds.YahooFinanceCSVData(\n        dataname=\"datas/orcl-1995-2014.txt\",\n        # Do not pass values before this date\n        fromdate=datetime.datetime(2000, 1, 1),\n        # Do not pass values after this date\n        todate=datetime.datetime(2000, 12, 31),\n        reverse=False)\n\n# print(data)\n\ncerebro.adddata(data)\n\ncerebro.broker.setcash(100000.0)\ncerebro.addsizer(bt.sizers.FixedSize, stake=10)\ncerebro.broker.setcommission(commission=0.001)\n\nprint('组合初始值: %.2f' % cerebro.broker.getvalue())\n\nresult=cerebro.run()\n\nprint('组合终结值: %.2f' % cerebro.broker.getvalue())\ncerebro.plot()\n\n组合初始值: 100000.00\nbuflen 252\n2000-02-18, Close, 26.05\n2000-02-22, Close, 26.38\n2000-02-22, BUY CREATE, 26.38\nRef: 81\nOrdType: 0\nOrdType: Buy\nStatus: 1\nStatus: Submitted\nSize: 10\nPrice: None\nPrice Limit: None\nTrailAmount: None\nTrailPercent: None\nExecType: 0\nExecType: Market\nCommInfo: None\nEnd of Session: 730172.9999999999\nInfo: AutoOrderedDict()\nBroker: None\nAlive: True\n2000-02-23, BUY EXECUTED, Price: 26.77, Cost: 267.70, Comm 0.27\n2000-02-23, Close, 28.05\n2000-02-24, Close, 27.55\n2000-02-25, Close, 31.41\n2000-02-28, Close, 30.52\n2000-02-29, Close, 33.02\n2000-03-01, Close, 31.80\n2000-03-02, Close, 30.47\n2000-03-03, Close, 33.36\n2000-03-06, Close, 33.69\n2000-03-07, Close, 33.33\n2000-03-08, Close, 36.97\n2000-03-09, Close, 37.36\n2000-03-10, Close, 36.30\n2000-03-13, Close, 35.02\n2000-03-14, Close, 34.25\n2000-03-15, Close, 34.97\n2000-03-16, Close, 36.44\n2000-03-17, Close, 35.50\n2000-03-20, Close, 34.75\n2000-03-21, Close, 35.89\n2000-03-22, Close, 37.39\n2000-03-23, Close, 38.64\n2000-03-24, Close, 38.69\n2000-03-27, Close, 39.33\n2000-03-28, Close, 38.50\n2000-03-29, Close, 36.69\n2000-03-30, Close, 34.88\n2000-03-30, SELL CREATE, 34.88\n2000-03-31, SELL EXECUTED, Price: 35.66, Cost: 267.70, Comm 0.36\n2000-03-31, OPERATION PROFIT, GROSS 88.90, NET 88.28\n2000-03-31, Close, 34.72\n2000-04-03, Close, 34.19\n2000-04-04, Close, 33.77\n2000-04-05, Close, 34.80\n2000-04-06, Close, 36.55\n2000-04-06, BUY CREATE, 36.55\nRef: 83\nOrdType: 0\nOrdType: Buy\nStatus: 1\nStatus: Submitted\nSize: 10\nPrice: None\nPrice Limit: None\nTrailAmount: None\nTrailPercent: None\nExecType: 0\nExecType: Market\nCommInfo: None\nEnd of Session: 730216.9999999999\nInfo: AutoOrderedDict()\nBroker: None\nAlive: True\n2000-04-07, BUY EXECUTED, Price: 37.22, Cost: 372.20, Comm 0.37\n2000-04-07, Close, 38.75\n2000-04-10, Close, 36.69\n2000-04-11, Close, 34.41\n2000-04-11, SELL CREATE, 34.41\n2000-04-12, SELL EXECUTED, Price: 34.66, Cost: 372.20, Comm 0.35\n2000-04-12, OPERATION PROFIT, GROSS -25.60, NET -26.32\n2000-04-12, Close, 32.52\n2000-04-13, Close, 31.99\n2000-04-14, Close, 27.80\n2000-04-17, Close, 33.27\n2000-04-18, Close, 35.11\n2000-04-18, BUY CREATE, 35.11\nRef: 85\nOrdType: 0\nOrdType: Buy\nStatus: 1\nStatus: Submitted\nSize: 10\nPrice: None\nPrice Limit: None\nTrailAmount: None\nTrailPercent: None\nExecType: 0\nExecType: Market\nCommInfo: None\nEnd of Session: 730228.9999999999\nInfo: AutoOrderedDict()\nBroker: None\nAlive: True\n2000-04-19, BUY EXECUTED, Price: 34.97, Cost: 349.70, Comm 0.35\n2000-04-19, Close, 33.16\n2000-04-19, SELL CREATE, 33.16\n2000-04-20, SELL EXECUTED, Price: 32.83, Cost: 349.70, Comm 0.33\n2000-04-20, OPERATION PROFIT, GROSS -21.40, NET -22.08\n2000-04-20, Close, 31.49\n2000-04-24, Close, 32.22\n2000-04-25, Close, 33.61\n2000-04-26, Close, 32.11\n2000-04-27, Close, 34.38\n2000-04-27, BUY CREATE, 34.38\nRef: 87\nOrdType: 0\nOrdType: Buy\nStatus: 1\nStatus: Submitted\nSize: 10\nPrice: None\nPrice Limit: None\nTrailAmount: None\nTrailPercent: None\nExecType: 0\nExecType: Market\nCommInfo: None\nEnd of Session: 730237.9999999999\nInfo: AutoOrderedDict()\nBroker: None\nAlive: True\n2000-04-28, BUY EXECUTED, Price: 34.91, Cost: 349.10, Comm 0.35\n2000-04-28, Close, 35.55\n2000-05-01, Close, 35.44\n2000-05-02, Close, 34.61\n2000-05-03, Close, 33.72\n2000-05-04, Close, 33.02\n2000-05-04, SELL CREATE, 33.02\n2000-05-05, SELL EXECUTED, Price: 32.91, Cost: 349.10, Comm 0.33\n2000-05-05, OPERATION PROFIT, GROSS -20.00, NET -20.68\n2000-05-05, Close, 34.16\n2000-05-05, BUY CREATE, 34.16\nRef: 89\nOrdType: 0\nOrdType: Buy\nStatus: 1\nStatus: Submitted\nSize: 10\nPrice: None\nPrice Limit: None\nTrailAmount: None\nTrailPercent: None\nExecType: 0\nExecType: Market\nCommInfo: None\nEnd of Session: 730245.9999999999\nInfo: AutoOrderedDict()\nBroker: None\nAlive: True\n2000-05-08, BUY EXECUTED, Price: 33.49, Cost: 334.90, Comm 0.33\n2000-05-08, Close, 32.16\n2000-05-08, SELL CREATE, 32.16\n2000-05-09, SELL EXECUTED, Price: 32.77, Cost: 334.90, Comm 0.33\n2000-05-09, OPERATION PROFIT, GROSS -7.20, NET -7.86\n2000-05-09, Close, 32.02\n2000-05-10, Close, 30.08\n2000-05-11, Close, 32.19\n2000-05-12, Close, 32.99\n2000-05-15, Close, 34.25\n2000-05-15, BUY CREATE, 34.25\nRef: 91\nOrdType: 0\nOrdType: Buy\nStatus: 1\nStatus: Submitted\nSize: 10\nPrice: None\nPrice Limit: None\nTrailAmount: None\nTrailPercent: None\nExecType: 0\nExecType: Market\nCommInfo: None\nEnd of Session: 730255.9999999999\nInfo: AutoOrderedDict()\nBroker: None\nAlive: True\n2000-05-16, BUY EXECUTED, Price: 34.52, Cost: 345.20, Comm 0.35\n2000-05-16, Close, 35.22\n2000-05-17, Close, 34.77\n2000-05-18, Close, 32.49\n2000-05-18, SELL CREATE, 32.49\n2000-05-19, SELL EXECUTED, Price: 32.02, Cost: 345.20, Comm 0.32\n2000-05-19, OPERATION PROFIT, GROSS -25.00, NET -25.67\n2000-05-19, Close, 31.16\n2000-05-22, Close, 30.16\n2000-05-23, Close, 27.85\n2000-05-24, Close, 28.57\n2000-05-25, Close, 29.55\n2000-05-26, Close, 29.80\n2000-05-30, Close, 32.99\n2000-05-30, BUY CREATE, 32.99\nRef: 93\nOrdType: 0\nOrdType: Buy\nStatus: 1\nStatus: Submitted\nSize: 10\nPrice: None\nPrice Limit: None\nTrailAmount: None\nTrailPercent: None\nExecType: 0\nExecType: Market\nCommInfo: None\nEnd of Session: 730270.9999999999\nInfo: AutoOrderedDict()\nBroker: None\nAlive: True\n2000-05-31, BUY EXECUTED, Price: 32.58, Cost: 325.80, Comm 0.33\n2000-05-31, Close, 31.97\n2000-06-01, Close, 34.63\n2000-06-02, Close, 35.66\n2000-06-05, Close, 36.00\n2000-06-06, Close, 34.27\n2000-06-07, Close, 35.58\n2000-06-08, Close, 36.64\n2000-06-09, Close, 36.77\n2000-06-12, Close, 35.83\n2000-06-13, Close, 36.33\n2000-06-14, Close, 35.13\n2000-06-15, Close, 36.69\n2000-06-16, Close, 36.41\n2000-06-19, Close, 38.25\n2000-06-20, Close, 38.27\n2000-06-21, Close, 38.33\n2000-06-22, Close, 36.25\n2000-06-22, SELL CREATE, 36.25\n2000-06-23, SELL EXECUTED, Price: 35.94, Cost: 325.80, Comm 0.36\n2000-06-23, OPERATION PROFIT, GROSS 33.60, NET 32.91\n2000-06-23, Close, 35.36\n2000-06-26, Close, 36.77\n2000-06-26, BUY CREATE, 36.77\nRef: 95\nOrdType: 0\nOrdType: Buy\nStatus: 1\nStatus: Submitted\nSize: 10\nPrice: None\nPrice Limit: None\nTrailAmount: None\nTrailPercent: None\nExecType: 0\nExecType: Market\nCommInfo: None\nEnd of Session: 730297.9999999999\nInfo: AutoOrderedDict()\nBroker: None\nAlive: True\n2000-06-27, BUY EXECUTED, Price: 36.64, Cost: 366.40, Comm 0.37\n2000-06-27, Close, 36.58\n2000-06-27, SELL CREATE, 36.58\n2000-06-28, SELL EXECUTED, Price: 36.50, Cost: 366.40, Comm 0.36\n2000-06-28, OPERATION PROFIT, GROSS -1.40, NET -2.13\n2000-06-28, Close, 36.89\n2000-06-28, BUY CREATE, 36.89\nRef: 97\nOrdType: 0\nOrdType: Buy\nStatus: 1\nStatus: Submitted\nSize: 10\nPrice: None\nPrice Limit: None\nTrailAmount: None\nTrailPercent: None\nExecType: 0\nExecType: Market\nCommInfo: None\nEnd of Session: 730299.9999999999\nInfo: AutoOrderedDict()\nBroker: None\nAlive: True\n2000-06-29, BUY EXECUTED, Price: 36.50, Cost: 365.00, Comm 0.36\n2000-06-29, Close, 35.97\n2000-06-29, SELL CREATE, 35.97\n2000-06-30, SELL EXECUTED, Price: 35.75, Cost: 365.00, Comm 0.36\n2000-06-30, OPERATION PROFIT, GROSS -7.50, NET -8.22\n2000-06-30, Close, 37.39\n2000-06-30, BUY CREATE, 37.39\nRef: 99\nOrdType: 0\nOrdType: Buy\nStatus: 1\nStatus: Submitted\nSize: 10\nPrice: None\nPrice Limit: None\nTrailAmount: None\nTrailPercent: None\nExecType: 0\nExecType: Market\nCommInfo: None\nEnd of Session: 730301.9999999999\nInfo: AutoOrderedDict()\nBroker: None\nAlive: True\n2000-07-03, BUY EXECUTED, Price: 36.08, Cost: 360.80, Comm 0.36\n2000-07-03, Close, 35.66\n2000-07-03, SELL CREATE, 35.66\n2000-07-05, SELL EXECUTED, Price: 34.16, Cost: 360.80, Comm 0.34\n2000-07-05, OPERATION PROFIT, GROSS -19.20, NET -19.90\n2000-07-05, Close, 32.16\n2000-07-06, Close, 33.63\n2000-07-07, Close, 33.75\n2000-07-10, Close, 32.97\n2000-07-11, Close, 32.16\n2000-07-12, Close, 33.22\n2000-07-13, Close, 33.69\n2000-07-14, Close, 33.86\n2000-07-17, Close, 33.86\n2000-07-18, Close, 32.99\n2000-07-19, Close, 32.80\n2000-07-20, Close, 34.75\n2000-07-20, BUY CREATE, 34.75\nRef: 101\nOrdType: 0\nOrdType: Buy\nStatus: 1\nStatus: Submitted\nSize: 10\nPrice: None\nPrice Limit: None\nTrailAmount: None\nTrailPercent: None\nExecType: 0\nExecType: Market\nCommInfo: None\nEnd of Session: 730321.9999999999\nInfo: AutoOrderedDict()\nBroker: None\nAlive: True\n2000-07-21, BUY EXECUTED, Price: 34.44, Cost: 344.40, Comm 0.34\n2000-07-21, Close, 33.55\n2000-07-21, SELL CREATE, 33.55\n2000-07-24, SELL EXECUTED, Price: 34.30, Cost: 344.40, Comm 0.34\n2000-07-24, OPERATION PROFIT, GROSS -1.40, NET -2.09\n2000-07-24, Close, 33.36\n2000-07-25, Close, 33.80\n2000-07-25, BUY CREATE, 33.80\nRef: 103\nOrdType: 0\nOrdType: Buy\nStatus: 1\nStatus: Submitted\nSize: 10\nPrice: None\nPrice Limit: None\nTrailAmount: None\nTrailPercent: None\nExecType: 0\nExecType: Market\nCommInfo: None\nEnd of Session: 730326.9999999999\nInfo: AutoOrderedDict()\nBroker: None\nAlive: True\n2000-07-26, BUY EXECUTED, Price: 33.27, Cost: 332.70, Comm 0.33\n2000-07-26, Close, 34.13\n2000-07-27, Close, 33.38\n2000-07-27, SELL CREATE, 33.38\n2000-07-28, SELL EXECUTED, Price: 33.41, Cost: 332.70, Comm 0.33\n2000-07-28, OPERATION PROFIT, GROSS 1.40, NET 0.73\n2000-07-28, Close, 32.19\n2000-07-31, Close, 33.44\n2000-07-31, BUY CREATE, 33.44\nRef: 105\nOrdType: 0\nOrdType: Buy\nStatus: 1\nStatus: Submitted\nSize: 10\nPrice: None\nPrice Limit: None\nTrailAmount: None\nTrailPercent: None\nExecType: 0\nExecType: Market\nCommInfo: None\nEnd of Session: 730332.9999999999\nInfo: AutoOrderedDict()\nBroker: None\nAlive: True\n2000-08-01, BUY EXECUTED, Price: 33.44, Cost: 334.40, Comm 0.33\n2000-08-01, Close, 32.52\n2000-08-01, SELL CREATE, 32.52\n2000-08-02, SELL EXECUTED, Price: 32.47, Cost: 334.40, Comm 0.32\n2000-08-02, OPERATION PROFIT, GROSS -9.70, NET -10.36\n2000-08-02, Close, 32.52\n2000-08-03, Close, 34.44\n2000-08-03, BUY CREATE, 34.44\nRef: 107\nOrdType: 0\nOrdType: Buy\nStatus: 1\nStatus: Submitted\nSize: 10\nPrice: None\nPrice Limit: None\nTrailAmount: None\nTrailPercent: None\nExecType: 0\nExecType: Market\nCommInfo: None\nEnd of Session: 730335.9999999999\nInfo: AutoOrderedDict()\nBroker: None\nAlive: True\n2000-08-04, BUY EXECUTED, Price: 34.83, Cost: 348.30, Comm 0.35\n2000-08-04, Close, 36.27\n2000-08-07, Close, 36.41\n2000-08-08, Close, 36.91\n2000-08-09, Close, 36.19\n2000-08-10, Close, 35.61\n2000-08-11, Close, 36.08\n2000-08-14, Close, 36.64\n2000-08-15, Close, 36.14\n2000-08-16, Close, 36.11\n2000-08-17, Close, 37.33\n2000-08-18, Close, 36.16\n2000-08-21, Close, 37.00\n2000-08-22, Close, 37.16\n2000-08-23, Close, 36.86\n2000-08-24, Close, 37.66\n2000-08-25, Close, 37.64\n2000-08-28, Close, 38.58\n2000-08-29, Close, 39.03\n2000-08-30, Close, 39.25\n2000-08-31, Close, 40.44\n2000-09-01, Close, 41.19\n2000-09-05, Close, 40.50\n2000-09-06, Close, 39.69\n2000-09-07, Close, 40.56\n2000-09-08, Close, 38.50\n2000-09-08, SELL CREATE, 38.50\n2000-09-11, SELL EXECUTED, Price: 38.28, Cost: 348.30, Comm 0.38\n2000-09-11, OPERATION PROFIT, GROSS 34.50, NET 33.77\n2000-09-11, Close, 37.11\n2000-09-12, Close, 35.30\n2000-09-13, Close, 36.39\n2000-09-14, Close, 37.78\n2000-09-15, Close, 34.83\n2000-09-18, Close, 34.01\n2000-09-19, Close, 35.27\n2000-09-20, Close, 35.55\n2000-09-21, Close, 35.11\n2000-09-22, Close, 35.91\n2000-09-25, Close, 35.02\n2000-09-26, Close, 35.33\n2000-09-27, Close, 35.52\n2000-09-28, Close, 36.24\n2000-09-28, BUY CREATE, 36.24\nRef: 109\nOrdType: 0\nOrdType: Buy\nStatus: 1\nStatus: Submitted\nSize: 10\nPrice: None\nPrice Limit: None\nTrailAmount: None\nTrailPercent: None\nExecType: 0\nExecType: Market\nCommInfo: None\nEnd of Session: 730391.9999999999\nInfo: AutoOrderedDict()\nBroker: None\nAlive: True\n2000-09-29, BUY EXECUTED, Price: 36.18, Cost: 361.80, Comm 0.36\n2000-09-29, Close, 35.02\n2000-09-29, SELL CREATE, 35.02\n2000-10-02, SELL EXECUTED, Price: 35.47, Cost: 361.80, Comm 0.35\n2000-10-02, OPERATION PROFIT, GROSS -7.10, NET -7.82\n2000-10-02, Close, 35.02\n2000-10-03, Close, 30.91\n2000-10-04, Close, 30.30\n2000-10-05, Close, 30.38\n2000-10-06, Close, 30.08\n2000-10-09, Close, 29.69\n2000-10-10, Close, 28.74\n2000-10-11, Close, 27.69\n2000-10-12, Close, 28.02\n2000-10-13, Close, 31.69\n2000-10-16, Close, 30.74\n2000-10-17, Close, 29.96\n2000-10-18, Close, 29.85\n2000-10-19, Close, 32.36\n2000-10-19, BUY CREATE, 32.36\nRef: 111\nOrdType: 0\nOrdType: Buy\nStatus: 1\nStatus: Submitted\nSize: 10\nPrice: None\nPrice Limit: None\nTrailAmount: None\nTrailPercent: None\nExecType: 0\nExecType: Market\nCommInfo: None\nEnd of Session: 730412.9999999999\nInfo: AutoOrderedDict()\nBroker: None\nAlive: True\n2000-10-20, BUY EXECUTED, Price: 32.13, Cost: 321.30, Comm 0.32\n2000-10-20, Close, 31.35\n2000-10-23, Close, 30.30\n2000-10-24, Close, 31.85\n2000-10-25, Close, 30.58\n2000-10-26, Close, 30.30\n2000-10-27, Close, 30.41\n2000-10-30, Close, 28.13\n2000-10-30, SELL CREATE, 28.13\n2000-10-31, SELL EXECUTED, Price: 29.02, Cost: 321.30, Comm 0.29\n2000-10-31, OPERATION PROFIT, GROSS -31.10, NET -31.71\n2000-10-31, Close, 29.35\n2000-11-01, Close, 27.91\n2000-11-02, Close, 26.30\n2000-11-03, Close, 26.96\n2000-11-06, Close, 24.85\n2000-11-07, Close, 23.63\n2000-11-08, Close, 22.07\n2000-11-09, Close, 24.18\n2000-11-10, Close, 22.63\n2000-11-13, Close, 22.01\n2000-11-14, Close, 25.24\n2000-11-15, Close, 25.68\n2000-11-16, Close, 24.35\n2000-11-17, Close, 25.63\n2000-11-17, BUY CREATE, 25.63\nRef: 113\nOrdType: 0\nOrdType: Buy\nStatus: 1\nStatus: Submitted\nSize: 10\nPrice: None\nPrice Limit: None\nTrailAmount: None\nTrailPercent: None\nExecType: 0\nExecType: Market\nCommInfo: None\nEnd of Session: 730441.9999999999\nInfo: AutoOrderedDict()\nBroker: None\nAlive: True\n2000-11-20, BUY EXECUTED, Price: 21.63, Cost: 216.30, Comm 0.22\n2000-11-20, Close, 22.01\n2000-11-20, SELL CREATE, 22.01\n2000-11-21, SELL EXECUTED, Price: 22.07, Cost: 216.30, Comm 0.22\n2000-11-21, OPERATION PROFIT, GROSS 4.40, NET 3.96\n2000-11-21, Close, 21.24\n2000-11-22, Close, 19.85\n2000-11-24, Close, 21.46\n2000-11-27, Close, 20.57\n2000-11-28, Close, 20.15\n2000-11-29, Close, 20.35\n2000-11-30, Close, 23.57\n2000-11-30, BUY CREATE, 23.57\nRef: 115\nOrdType: 0\nOrdType: Buy\nStatus: 1\nStatus: Submitted\nSize: 10\nPrice: None\nPrice Limit: None\nTrailAmount: None\nTrailPercent: None\nExecType: 0\nExecType: Market\nCommInfo: None\nEnd of Session: 730454.9999999999\nInfo: AutoOrderedDict()\nBroker: None\nAlive: True\n2000-12-01, BUY EXECUTED, Price: 23.46, Cost: 234.60, Comm 0.23\n2000-12-01, Close, 23.52\n2000-12-04, Close, 25.07\n2000-12-05, Close, 28.02\n2000-12-06, Close, 26.85\n2000-12-07, Close, 25.18\n2000-12-08, Close, 26.74\n2000-12-11, Close, 28.41\n2000-12-12, Close, 27.35\n2000-12-13, Close, 25.24\n2000-12-14, Close, 24.46\n2000-12-14, SELL CREATE, 24.46\n2000-12-15, SELL EXECUTED, Price: 26.18, Cost: 234.60, Comm 0.26\n2000-12-15, OPERATION PROFIT, GROSS 27.20, NET 26.70\n2000-12-15, Close, 25.41\n2000-12-15, BUY CREATE, 25.41\nRef: 117\nOrdType: 0\nOrdType: Buy\nStatus: 1\nStatus: Submitted\nSize: 10\nPrice: None\nPrice Limit: None\nTrailAmount: None\nTrailPercent: None\nExecType: 0\nExecType: Market\nCommInfo: None\nEnd of Session: 730469.9999999999\nInfo: AutoOrderedDict()\nBroker: None\nAlive: True\n2000-12-18, BUY EXECUTED, Price: 26.68, Cost: 266.80, Comm 0.27\n2000-12-18, Close, 28.46\n2000-12-19, Close, 27.24\n2000-12-20, Close, 25.35\n2000-12-20, SELL CREATE, 25.35\n2000-12-21, SELL EXECUTED, Price: 24.74, Cost: 266.80, Comm 0.25\n2000-12-21, OPERATION PROFIT, GROSS -19.40, NET -19.91\n2000-12-21, Close, 26.24\n2000-12-21, BUY CREATE, 26.24\nRef: 119\nOrdType: 0\nOrdType: Buy\nStatus: 1\nStatus: Submitted\nSize: 10\nPrice: None\nPrice Limit: None\nTrailAmount: None\nTrailPercent: None\nExecType: 0\nExecType: Market\nCommInfo: None\nEnd of Session: 730475.9999999999\nInfo: AutoOrderedDict()\nBroker: None\nAlive: True\n2000-12-22, BUY EXECUTED, Price: 27.02, Cost: 270.20, Comm 0.27\n2000-12-22, Close, 28.35\n2000-12-26, Close, 27.52\n2000-12-27, Close, 27.30\n2000-12-28, Close, 27.63\n2000-12-29, Close, 25.85\n2000-12-29, SELL CREATE, 25.85\n组合终结值: 99969.64\n\n\n\n\n\n\n\n\n[[&lt;Figure size 640x480 with 8 Axes&gt;]]"
  }
]